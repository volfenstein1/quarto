[
  {
    "objectID": "fastai-3.5.html",
    "href": "fastai-3.5.html",
    "title": "Fitting a function with gradient descent",
    "section": "",
    "text": "A neural network is just a mathematical function. In the most standard kind of neural network, the function:\nThis represents one “layer”. Then these three steps are repeated, using the outputs of the previous layer as the inputs to the next layer. Initially, the parameters in this function are selected randomly. Therefore a newly created neural network doesn’t do anything useful at all – it’s just random!\nTo get the function to “learn” to do something useful, we have to change the parameters to make them “better” in some way. We do this using gradient descent. Let’s see how this works…\n::: {#c62a043f .cell _kg_hide-input=‘true’ execution=‘{“iopub.execute_input”:“2023-04-26T12:37:19.419937Z”,“iopub.status.busy”:“2023-04-26T12:37:19.419421Z”,“iopub.status.idle”:“2023-04-26T12:37:22.523175Z”,“shell.execute_reply”:“2023-04-26T12:37:22.522149Z”}’ papermill=‘{“duration”:3.158556,“end_time”:“2023-04-26T12:37:22.525730”,“exception”:false,“start_time”:“2023-04-26T12:37:19.367174”,“status”:“completed”}’ tags=‘[]’ execution_count=1}\n:::\nTo learn how gradient descent works, we’re going to start by fitting a quadratic, since that’s a function most of us are probably more familiar with than a neural network. Here’s the quadratic we’re going to try to fit:\ndef f(x): return 3*x**2 + 2*x + 1\n\nplot_function(f, \"$3x^2 + 2x + 1$\")\nThis quadratic is of the form \\(ax^2+bx+c\\), with parameters \\(a=3\\), \\(b=2\\), \\(c=1\\). To make it easier to try out different quadratics for fitting a model to the data we’ll create, let’s create a function that calculates the value of a point on any quadratic:\ndef quad(a, b, c, x): return a*x**2 + b*x + c\nIf we fix some particular values of a, b, and c, then we’ll have made a quadratic. To fix values passed to a function in python, we use the partial function, like so:\ndef mk_quad(a,b,c): return partial(quad, a,b,c)\nSo for instance, we can recreate our previous quadratic:\nf2 = mk_quad(3,2,1)\nplot_function(f2)\nNow let’s simulate making some noisy measurements of our quadratic f. We’ll then use gradient descent to see if we can recreate the original function from the data.\nHere’s a couple of functions to add some random noise to data:\ndef noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\ndef add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\nLet’s use the now to create our noisy measurements based on the quadratic above:\nnp.random.seed(42)\n\nx = torch.linspace(-2, 2, steps=20)[:,None]\ny = add_noise(f(x), 0.15, 1.5)\nHere’s the first few values of each of x and y:\nx[:5],y[:5]\n\n(tensor([[-2.0000],\n         [-1.7895],\n         [-1.5789],\n         [-1.3684],\n         [-1.1579]]),\n tensor([[11.8690],\n         [ 6.5433],\n         [ 5.9396],\n         [ 2.6304],\n         [ 1.7947]], dtype=torch.float64))\nAs you can see, they’re tensors. A tensor is just like an array in numpy (if you’re not familiar with numpy, I strongly recommend reading this great book, because it’s a critical foundation for nearly all numeric programming in Python. Furthermore, PyTorch, which most researchers use for deep learning, is modeled closely on numpy.) A tensor can be a single number (a scalar or rank-0 tensor), a list of numbers (a vector or rank-1 tensor), a table of numbers (a matrix or rank-2 tensor), a table of tables of numbers (a rank-3 tensor), and so forth.\nWe’re not going to learn much about our data by just looking at the raw numbers, so let’s draw a picture:\nplt.scatter(x,y);\nHow do we find values of a, b, and c which fit this data? One approach is to try a few values and see what fits. Here’s a function which overlays a quadratic on top of our data, along with some sliders to change a, b, and c, and see how it looks:\n@interact(a=1.1, b=1.1, c=1.1)\ndef plot_quad(a, b, c):\n    plt.scatter(x,y)\n    plot_function(mk_quad(a,b,c), ylim=(-3,13))\nReminder: If the sliders above aren’t working for you, that’s because the interactive features of this notebook don’t work in Kaggle’s Reader mode. They only work in Edit mode. Please click “Copy & Edit” in the top right of this window, then in the menu click Run and then Run all. Then you’ll be able to use all the interactive sliders in this notebook.\nTry moving slider a a bit to the left. Does that look better or worse? How about if you move it a bit to the right? Find out which direction seems to improve the fit of the quadratic to the data, and move the slider a bit in that direction. Next, do the same for slider b: first figure out which direction improves the fit, then move it a bit in that direction. Then do the same for c.\nOK, now go back to slider a and repeat the process. Do it again for b and c as well.\nDid you notice that by going back and doing the sliders a second time that you were able to improve things a bit further? That’s an important insight – it’s only after changing b and c, for instance, that you realise that a actually needs some adjustment based on those new values.\nOne thing that’s making this tricky is that we don’t really have a great sense of whether our fit is really better or worse. It would be easier if we had a numeric measure of that. On easy metric we could use is mean absolute error – which is the distance from each data point to the curve:\ndef mae(preds, acts): return (torch.abs(preds-acts)).mean()\nWe’ll update our interactive function to print this at the top for us.\nUse this to repeat the approach we took before to try to find the best fit, but this time just use the value of the metric to decide which direction to move each slider, and how far to move it.\nThis time around, try doing it in the opposite order: c, then b, then a.\nYou’ll probably find that you have to go through the set of sliders a couple of times to get the best fit.\n@interact(a=1.1, b=1.1, c=1.1)\ndef plot_quad(a, b, c):\n    f = mk_quad(a,b,c)\n    plt.scatter(x,y)\n    loss = mae(f(x), y)\n    plot_function(f, ylim=(-3,12), title=f\"MAE: {loss:.2f}\")\nIn a modern neural network we’ll often have tens of millions of parameters to fit, or more, and thousands or millions of data points to fit them to. We’re not going to be able to do that by moving sliders around! We’ll need to automate this process.\nThankfully, that turns out to be pretty straightforward. We can use calculus to figure out, for each parameter, whether we should increase or decrease it.\nUh oh, calculus! If you haven’t touched calculus since school, you might be getting ready to run away at this point. But don’t worry, we don’t actually need much calculus at all. Just derivatives, which measure the rate of change of a function. We don’t even need to calculate them ourselves, because the computer will do it for us! If you’ve forgotten what a derivitive is, then watch the first three of these fantastic videos by Professor Dave. It’s only 15 minutes in total, so give it a go! Then come back here and we’ll continue on our journey…",
    "crumbs": [
      "Deep Learning",
      "Fitting a function with *gradient descent*"
    ]
  },
  {
    "objectID": "fastai-3.5.html#automating-gradient-descent",
    "href": "fastai-3.5.html#automating-gradient-descent",
    "title": "Fitting a function with gradient descent",
    "section": "Automating gradient descent",
    "text": "Automating gradient descent\nThe basic idea is this: if we know the gradient of our mae() function with respect to our parameters, a, b, and c, then that means we know how adjusting (for instance) a will change the value of mae(). If, say, a has a negative gradient, then we know that increasing a will decrease mae(). Then we know that’s what we need to do, since we trying to make mae() as low as possible.\nSo, we find the gradient of mae() for each of our parameters, and then adjust our parameters a bit in the opposite direction to the sign of the gradient.\nTo do this, first we need a function that takes all the parameters a, b, and c as a single vector input, and returns the value mae() based on those parameters:\n\ndef quad_mae(params):\n    f = mk_quad(*params)\n    return mae(f(x), y)\n\nLet’s try it:\n\nquad_mae([1.1, 1.1, 1.1])\n\ntensor(2.4219, dtype=torch.float64)\n\n\nYup, that’s the same as the starting mae() we had in our plot before.\nWe’re first going to do exactly the same thing as we did manually – pick some arbritrary starting point for our parameters. We’ll put them all into a single tensor:\n\nabc = torch.tensor([1.1,1.1,1.1])\n\nTo tell PyTorch that we want it to calculate gradients for these parameters, we need to call requires_grad_():\n\nabc.requires_grad_()\n\ntensor([1.1000, 1.1000, 1.1000], requires_grad=True)\n\n\nWe can now calculate mae(). Generally, when doing gradient descent, the thing we’re trying to minimise is called the loss:\n\nloss = quad_mae(abc)\nloss\n\ntensor(2.4219, dtype=torch.float64, grad_fn=&lt;MeanBackward0&gt;)\n\n\nTo get PyTorch to now calculate the gradients, we need to call backward()\n\nloss.backward()\n\nThe gradients will be stored for us in an attribute called grad:\n\nabc.grad\n\ntensor([-1.3529, -0.0316, -0.5000])\n\n\nAccording to these gradients, all our parameters are a little low. So let’s increase them a bit. If we subtract the gradient, multiplied by a small number, that should improve them a bit:\n\nwith torch.no_grad():\n    abc -= abc.grad*0.01\n    loss = quad_mae(abc)\n    \nprint(f'loss={loss:.2f}')\n\nloss=2.40\n\n\nYes, our loss has gone down!\nThe “small number” we multiply is called the learning rate, and is the most important hyper-parameter to set when training a neural network.\nBTW, you’ll see we had to wrap our calculation of the new parameters in with torch.no_grad(). That disables the calculation of gradients for any operations inside that context manager. We have to do that, because abc -= abc.grad*0.01 isn’t actually part of our quadratic model, so we don’t want derivitives to include that calculation.\nWe can use a loop to do a few more iterations of this:\n\nfor i in range(10):\n    loss = quad_mae(abc)\n    loss.backward()\n    with torch.no_grad(): abc -= abc.grad*0.01\n    print(f'step={i}; loss={loss:.2f}')\n\nstep=0; loss=2.40\nstep=1; loss=2.36\nstep=2; loss=2.30\nstep=3; loss=2.21\nstep=4; loss=2.11\nstep=5; loss=1.98\nstep=6; loss=1.85\nstep=7; loss=1.72\nstep=8; loss=1.58\nstep=9; loss=1.46\n\n\nAs you can see, our loss keeps going down!\nIf you keep running this loop for long enough however, you’ll see that the loss eventually starts increasing for a while. That’s because once the parameters get close to the correct answer, our parameter updates will jump right over the correct answer! To avoid this, we need to decrease our learning rate as we train. This is done using a learning rate schedule, and can be automated in most deep learning frameworks, such as fastai and PyTorch.",
    "crumbs": [
      "Deep Learning",
      "Fitting a function with *gradient descent*"
    ]
  },
  {
    "objectID": "fastai-3.5.html#how-a-neural-network-approximates-any-given-function",
    "href": "fastai-3.5.html#how-a-neural-network-approximates-any-given-function",
    "title": "Fitting a function with gradient descent",
    "section": "How a neural network approximates any given function",
    "text": "How a neural network approximates any given function\nBut neural nets are much more convenient and powerful than this example showed, because we can learn much more than just a quadratic with them. How does that work?\nThe trick is that a neural network is a very expressive function. In fact – it’s infinitely expressive. A neural network can approximate any computable function, given enough parameters. A “computable function” can cover just about anything you can imagine: understand and translate human speech; paint a picture; diagnose a disease from medical imaging; write an essay; etc…\nThe way a neural network approximates a function actually turns out to be very simple. The key trick is to combine two extremely basic steps:\n\nMatrix multiplication, which is just multiplying things together and then adding them up\nThe function \\(max(x,0)\\), which simply replaces all negative numbers with zero.\n\nIn PyTorch, the function \\(max(x,0)\\) is written as np.clip(x,0). The combination of a linear function and this max() is called a rectified linear function, and it can be implemented like this:\n\ndef rectified_linear(m,b,x):\n    y = m*x+b\n    return torch.clip(y, 0.)\n\nHere’s what it looks like:\n\nplot_function(partial(rectified_linear, 1,1))\n\n\n\n\n\n\n\n\nBTW, instead of torch.clip(y, 0.), we can instead use F.relu(x), which does exactly the same thing. In PyTorch, F refers to the torch.nn.functional module.\n\nimport torch.nn.functional as F\ndef rectified_linear2(m,b,x): return F.relu(m*x+b)\nplot_function(partial(rectified_linear2, 1,1))\n\n\n\n\n\n\n\n\nTo understand how this function works, try using this interactive version to play around with the parameters m and b:\n\n@interact(m=1.5, b=1.5)\ndef plot_relu(m, b):\n    plot_function(partial(rectified_linear, m,b), ylim=(-1,4))\n\n\n\n\nAs you see, m changes the slope, and b changes where the “hook” appears. This function doesn’t do much on its own, but look what happens when we add two of them together:\n\ndef double_relu(m1,b1,m2,b2,x):\n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x)\n\n@interact(m1=-1.5, b1=-1.5, m2=1.5, b2=1.5)\ndef plot_double_relu(m1, b1, m2, b2):\n    plot_function(partial(double_relu, m1,b1,m2,b2), ylim=(-1,6))\n\n\n\n\nIf you play around with that for a while, you notice something quite profound: with enough of these rectified linear functions added together, you could approximate any function with a single input, to whatever accuracy you like! Any time the function doesn’t quite match, you can just add a few more additions to the mix to make it a bit closer. As an experiment, perhaps you’d like to try creating your own plot_triple_relu interactive function, and maybe even include the scatter plot of our data from before, to see how close you can get?\nThis exact same approach can be expanded to functions of 2, 3, or more parameters.",
    "crumbs": [
      "Deep Learning",
      "Fitting a function with *gradient descent*"
    ]
  },
  {
    "objectID": "fastai-3.5.html#how-to-recognise-an-owl",
    "href": "fastai-3.5.html#how-to-recognise-an-owl",
    "title": "Fitting a function with gradient descent",
    "section": "How to recognise an owl",
    "text": "How to recognise an owl\nOK great, we’ve created a nifty little example showing that we can drawing squiggly lines that go through some points. So what?\nWell… the truth is that actually drawing squiggly lines (or planes, or high-dimensional hyperplanes…) through some points is literally all that deep learning does! If your data points are, say, the RGB values of pixels in photos of owls, then you can create an owl-recogniser model by following the exact steps above.\nThis may, at first, sound about as useful as the classic “how to draw an owl” guide:\n\n\n\nimage.png\n\n\nStudents often ask me at this point “OK Jeremy, but how do neural nets actually work”. But at a foundational level, there is no “step 2”. We’re done – the above steps will, given enough time and enough data, create (for example) an owl recogniser, if you feed in enough owls (and non-owls).\nThe devil, I guess, is in the “given enough time and enough data” part of the above sentence. There’s a lot of tweaks we can make to reduce both of these things. For instance, instead of running our calculations on a normal CPU, as we’ve done above, we could do thousands of them simultaneously by taking advantage of a GPU. We could greatly reduce the amount of computation and data needed by using a convolution instead of a matrix multiplication, which basically means skipping over a bunch of the multiplications and additions for bits that you’d guess won’t be important. We could make things much faster if, instead of starting with random parameters, we start with parameters of someone else’s model that does something similar to what we want (this is called transfer learning).\nAnd, of course, there’s lots of helpful software out there to do this stuff for you without too much fuss. Like, say, fastai.\nLearning these things is what we teach in our course, which, like everything we make, is totally free. So if you’re interested in learning more, do check it out!\nAs always, if you enjoyed this notebook, please upvote it to help others find it, and to encourage me to write more. If you upvote it, be careful you don’t accidentally upvote your copy that’s created when you click “Copy & Edit” – you can find my original at this link.",
    "crumbs": [
      "Deep Learning",
      "Fitting a function with *gradient descent*"
    ]
  },
  {
    "objectID": "mathematics.html",
    "href": "mathematics.html",
    "title": "Mathematics",
    "section": "",
    "text": "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Standard Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%mathbb \n%greek \n%GREEK \n%cal \n%tilde \n%bar % \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Math Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%compactified moduli space \n% % % % %SYMPLECTIC GEOMETRY % % % % % \n% % % % %Hat Delbar % % % % % \n% % % % %COLORS % % % % %\n% % % % %GROMOV-WITTEN LANGUAGE % % % % % \n% % % % %THOM LANGUAGE % % % % % \n% % % % %POLYFOLD LANGUAGE % % % % %",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#my-research-accomplishments",
    "href": "mathematics.html#my-research-accomplishments",
    "title": "Mathematics",
    "section": "My research accomplishments",
    "text": "My research accomplishments\nIn 1994, Kontsevich and Manin stated the Gromov–Witten axioms. At the time, it was not possible for them to give a complete proof; the field of Gromov–Witten theory was premature, and it would take years for a mathematically rigorous definition of a Gromov–Witten invariant to develop. In 2017, polyfold theory, as developed by Hofer, Wysocki, and Zehnder, was successful in giving a well-defined Gromov–Witten invariant for general symplectic manifolds.\nThe focus of my mathematical career has been in giving a complete proof of the Gromov–Witten axioms using the tools and techniques of polyfold Gromov–Witten invariants. In 2019, I succeeded in this research project.\nMy research accomplishments to date are the following:\n\nFollowing the work of Thom, I solved the Steenrod problem for closed orientable orbifolds, proving that the rational homology groups of a closed orientable orbifold have a basis consisting of classes represented by closed embedded full suborbifolds whose normal bundles have fiberwise trivial isotropy action.\nI proved that the polyfold Gromov–Witten invariants, originally defined via integration of differential forms, may equivalently be defined as intersection numbers against a basis of representing suborbifolds.\nI provided a general framework for proving that polyfold invariants are natural, and in particular demonstrated that the polyfold Gromov–Witten invariants do not depend on auxiliary choices.\nI constructed the universal curve polyfold on which it is possible to define the \\(k\\)th-marked point forgetting map and to pullback abstract perturbations.\nI gave a complete proof of the Gromov–Witten axioms for the polyfold Gromov–Witten invariants.\nI showed that the classical pseudocycle Gromov–Witten invariants, defined for semipositive symplectic manifolds, are a strict subset of the more general polyfold Gromov–Witten invariants.",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#history-of-the-gromovwitten-axioms",
    "href": "mathematics.html#history-of-the-gromovwitten-axioms",
    "title": "Mathematics",
    "section": "History of the Gromov–Witten axioms",
    "text": "History of the Gromov–Witten axioms\nIn 1985 Gromov published the paper “Pseudo holomorphic curves in symplectic manifolds”, laying the foundations for the modern study of pseudo holomorphic curves (also know as \\(J\\)-holomorphic curves) in symplectic topology (Gromov 1985). In this paper, Gromov proved a compactness result for the moduli space of \\(J\\)-holomorphic curves in a fixed homology class. This paper contained antecedents to the modern notion of the Gromov–Witten invariants in the proofs of the nonsqueezing theorem and the uniqueness of symplectic structures on \\(\\mathbb{C}P^2\\).\nAround 1988, inspired by Floer’s study of gauge theory on three manifolds, Witten introduced the topological sigma model (Floer 1988; Witten 1988). The invariants of this model are the “\\(k\\)-point correlation functions”, another precursor to the modern notion of the Gromov–Witten invariants. Witten also observed some of the relationships between these invariants and possible degenerations of Riemann surfaces (Witten 1991). Further precursors to the notion of the Gromov–Witten invariants can also be seen in McDuff’s classification of symplectic ruled surfaces (McDuff 1991).\nIn 1993 Ruan gave a modern definition of the genus-zero Gromov–Witten invariants for semipositive symplectic manifolds (Ruan 1996, 1994). At the end of 1993, Ruan and Tian established the associativity of the quantum product for semipositive symplectic manifolds, giving a mathematical basis to the composition law of Witten’s topological sigma model (Ruan and Tian 1995).\nIn 1994 Kontsevich and Manin stated the Gromov–Witten axioms, given as a list of formal relations between the Gromov–Witten invariants (Kontsevich and Manin 1994). At the time it was not possible for Kontsevich and Manin to give a proof of the relations they listed; the definition of the Gromov–Witten invariant (complete with homology classes from a Deligne–Mumford space) would require in addition new ideas involving “stable maps” (Kontsevich 1995). Hence they used to term “axiom” with the presumed meaning “to take for assumption without proof”/ “to use as a premise for further reasoning”. And indeed, from these starting assumptions they were able to establish foundational results in enumerative geometry, answers to esoteric questions such as:\n\nKontsevich’s recursion formula. Let \\(d\\geq 1\\). How many degree \\(d\\) rational curves in \\(\\mathbb{C}P^2\\) pass through \\(3d - 1\\) points in general position?\n\nMoreover, in this paper they outlined some of the formal consequences of the axioms by demonstrating how to combine the invariants into a Gromov–Witten potential, and interpret the axioms as differential equations which the potential satisfies.\nTo varying extents, this work has predated the construction of a well-defined Gromov–Witten invariant in symplectic geometry for \\(J\\)-holomorphic curves of arbitrary genus, and for all closed symplectic manifolds. Efforts to construct a well-defined Gromov–Witten invariant constitute an ever growing list of publications, including but not limited to the following: (Li and Tian 1998; Fukaya and Ono 1999; Fukaya et al. 2012; Siebert 1996; Cieliebak and Mohnke 2007; McDuff and Wehrheim 2012, 2018, 2017; Ionel and Parker 2013; Pardon 2016). A discussion of some of the difficulties inherent in these approaches can be found in (Fabert et al. 2016). Similarly, there have been several efforts to prove the Gromov–Witten axioms (Fukaya and Ono 1999; McDuff and Salamon 2012; Castellano 2016).\nOver the past two decades, Hofer, Wysocki, and Zehnder have developed a new approach to resolving transversality issues that arise in the study of \\(J\\)-holomorphic curves in symplectic geometry called polyfold theory (Hofer, Wysocki, and Zehnder 2007, 2009a, 2009b, 2017a, 2010b, n.d., 2010a, 2017b). This approach has been successful in constructing a well-defined Gromov–Witten invariant for arbitrary genus and for general symplectic manifolds (Hofer, Wysocki, and Zehnder 2017a).\nWith a fully general Gromov–Witten invariant finally defined rigorously, my research has fixated on answering the following question:\n\nIs it possible to finally prove the Gromov–Witten axioms using polyfold theory?",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#what-is-a-gromovwitten-invariant",
    "href": "mathematics.html#what-is-a-gromovwitten-invariant",
    "title": "Mathematics",
    "section": "What is a Gromov–Witten invariant?",
    "text": "What is a Gromov–Witten invariant?\nLet \\((M,\\omega)\\) be a closed symplectic manifold of dimension \\(\\dim M = 2n\\), and let \\(J\\) be a \\(\\omega\\)-compatible almost complex structure. For a fixed homology class \\(A\\in H_2(M,{\\mathbb Z})\\), and for fixed integers \\(g\\geq 0\\), \\(k\\geq 0\\), we consider the set of \\(J\\)-holomorphic curves:\n\\[\n    {\\mathcal M}_{A,g,k}(J) :=\n    \\left\\{\n    \\begin{array}{c}\n        u: (\\Sigma_g,j) \\to M \\\\\n        \\{z_1,\\ldots,z_k\\}\\in \\Sigma_g\n    \\end{array}\n    \\biggm|\n    \\begin{array}{c}\n        \\tfrac{1}{2} (du+J\\circ du\\circ j)=0 \\\\\n        u_*[\\Sigma_g] = A\n    \\end{array}\n    \\right\\}\n    \\biggm/\n    \\begin{array}{l}\n        u \\sim u\\circ \\phi, \\\\\n        \\phi\\in \\text{Aut}\n    \\end{array}\n\\]\nconsisting of smooth maps \\(u:(\\Sigma_g,j)\\to M\\) which satisfy the Cauchy–Riemann equation modulo reparametrization; here \\((\\Sigma_g,j)\\) is a genus \\(g\\) Riemann surface and \\(\\text{Aut}\\) is the automorphism group of the Riemann surface \\((\\Sigma_g,j)\\) which preserves the ordering of the marked points.\nGromov proved this set has a natural compactification in (Gromov 1985), which was later refined into the stable map compactification of Kontsevich in (Kontsevich 1995), and thus we may also consider its compactification, the Gromov–Witten moduli space:\n\\[\n    \\bar{\\mathcal{M}}_{A,g,k} (J) := {\\mathcal M}_{A,g,k} (J) \\sqcup \\{\\text{stable nodal $J$-holomorphic curves}\\}.\n\\]\nWe seek to use this space to construct invariants of the symplectic manifold \\(M\\). To this end, we define the evaluation map which evaluates a stable curve on each marked point:\n\\[\n    ev: \\bar{\\mathcal{M}}_{A,g,k} (J) \\to M\\times \\cdots \\times M.\n\\]\nOn the top stratum of non-noded stable \\(J\\)-holomorphic curves it is given by\n\\[\n    ev\\left([(u,z_1,\\ldots,z_k)] \\right): = (u(z_1),\\ldots, u(z_k)).\n\\]\nWith the fixed integers \\(g \\geq 0\\), \\(k \\geq 3\\) we also consider the associated Deligne–Mumford space, the natural compactification of the space of configurations of a complex structure and \\(k\\)-marked points on a genus \\(g\\) Riemann surface modulo biholomorphic equivalence:\n\\[\n    \\bar{\\mathcal{M}}_{g,k} := \\text{cl} \\left(\\{ j, \\{z_1,\\ldots,z_k\\}\\in \\Sigma_g \\mid j \\text{ complex structure on } \\Sigma_g, z_i\\neq z_j \\text{ if } i \\neq j\\} / \\text{Aut} \\right).\n\\]\nWhen \\(g = 0\\) this space is a finite-dimensional manifold, and when \\(g\\neq 0\\) this space is a finite-dimensional orbifold, in either case of dimension \\(\\text{dim}\\) \\(\\bar{\\mathcal{M}}_{g,k} = 6g - 6 + 2k\\) We may define a projection map from the Gromov–Witten moduli space to the Deligne–Mumford space which forgets the curve which maps to \\(M\\) and which stabilizes the resulting unstable domain components:\n\\[\n    \\pi: \\bar{\\mathcal{M}}_{A,g,k} (J) \\to \\bar{\\mathcal{M}}_{g,k}.\n\\]\nOn the top stratum of non-noded stable \\(J\\)-holomorphic curves it forgets the map \\(u\\) and is given by\n\\[\n    \\pi\\left([(u,j,z_1,\\ldots,z_k)]\\right) := [(j,z_1,\\ldots,z_k)].\n\\]\nThe traditional interpretation of a Gromov–Witten invariant is the (supposedly) finite count of \\(J\\)-holomorphic curves which at the \\(i\\)th-marked point pass through a submanifold \\({\\mathcal X}_i \\subset M\\) and whose marked point configuration is restricted by the projection map to a suborbifold \\({\\mathcal B}\\subset \\bar{\\mathcal{M}}_{g,k}\\). This can be visualized as the intersection number of the Gromov–Witten moduli space \\(\\bar{\\mathcal{M}}_{A,g,k}(J)\\) with the product suborbifold \\({\\mathcal X}_1\\times \\cdots \\times {\\mathcal X}_k \\times {\\mathcal B}\\) via the map \\(ev_1\\times \\cdots \\times ev_k \\times \\pi\\) as depicted in the following diagram:\n\\[\n\\begin{align*}\n\\bar{\\mathcal{M}}_{A,g,k}(J) \\xrightarrow{ev_1\\times \\cdots \\times ev_k \\times \\pi} M\\times \\cdots & \\times M \\times \\bar{\\mathcal{M}}_{g,k} \\\\\n                                                                                                                                                    & \\cup \\\\\n                                                                                                                    {\\mathcal X}_1\\times \\cdots &\\times {\\mathcal X}_k \\times {\\mathcal B}.\n\\end{align*}\n\\]\nSuch an intersection number should depend only on the homology classes of the submanifolds / suborbifolds, and should be independent of the almost complex structure. This count can be packaged algebraically as a homomorphism:\n\\[\n    \\mathop{\\mathrm{GW}}_{A,g,k} : H_*(M;{\\mathbb Q})^{\\otimes k} \\times H_*(\\bar{\\mathcal{M}}_{g,k};{\\mathbb Q}) \\to {\\mathbb Q}.\n\\]\nA foundational problem in symplectic geometry is to actually show that such a Gromov–Witten invariant is well-defined. Ideally, we would like to define a Gromov–Witten invariant rigorously via an intersection number:\n\\[\n\\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) = (ev\\times \\pi) (\\bar{\\mathcal{M}}_{A,g,k} (J)) \\cdot ({\\mathcal X}_1\\times \\cdots \\times {\\mathcal X}_k \\times {\\mathcal B}),\n\\]\nor as an integral:\n\\[\n\\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) = \\int_{\\bar{\\mathcal{M}}_{A,g,k}(J)} ev^* (\\mathop{\\mathrm{PD}}[{\\mathcal X}_1]\\wedge \\cdots \\wedge \\mathop{\\mathrm{PD}}[{\\mathcal X}_k]) \\wedge \\pi^* \\mathop{\\mathrm{PD}}[{\\mathcal B}],\n\\]\nor as a pairing with a (virtual) fundamental class:\n\\[\n\\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) = \\left\\langle (ev\\times\\pi)_* [\\bar{\\mathcal{M}}_{A,g,k}(J)], \\mathop{\\mathrm{PD}}[{\\mathcal X}_1\\times\\cdots\\times{\\mathcal X}_k\\times{\\mathcal B}] \\right\\rangle.\n\\]\nSuch definitions require additional structure on the Gromov–Witten moduli space; an intersection number requires tangent spaces and notions of transversal intersection, an integral requires smooth partitions of unity and notions of differential forms, and a (virtual) fundamental class requires a distinguished homology class on the topological space.\nHowever, a priori, the Gromov–Witten moduli space only has the structure of a compact topological space, and this alone is insufficient to define any of the above. More structure is needed.",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#the-classical-pseudocycle-gromovwitten-invariant",
    "href": "mathematics.html#the-classical-pseudocycle-gromovwitten-invariant",
    "title": "Mathematics",
    "section": "The classical pseudocycle Gromov–Witten invariant",
    "text": "The classical pseudocycle Gromov–Witten invariant\nThe classical approach to defining the Gromov–Witten invariants is to show that the Gromov–Witten moduli space has the structure of a pseudocycle.\nIf the Cauchy–Riemann section were completely transversal to the zero section, i.e., transversal when considered on all possible nodal strata of the space of \\(J\\)-curves, then the top stratum of the space of \\(J\\)-curves would have the structure of a finite-dimensional manifold and all nodal strata would have the structure of manifolds with codimension at least \\(2\\) relative to the top stratum. Thus the space of \\(J\\)-curves would have the structure of a “pseudocycle”, i.e., a space whose boundary (the nodal strata) would be invisible from the point of view of homology.\nDefinition. Let \\(M\\) be a smooth manifold. A smooth map \\(f: V \\to M\\) is a \\(d\\)-dimensional pseudocycle if \\(V\\) is an oriented \\(d\\)-dimensional manifold \\(V\\) such that the image \\(f(V)\\) has compact closure and such that the image of the boundary \\(f(\\bar{V} \\setminus V)\\) has dimension at most \\(\\leq d - 2\\).\nPseudocycles have sufficient structure for defining intersection numbers, as for dimension reasons the boundary will not contribute to the intersection number.\nHowever, transversality of the Cauchy–Riemann section is often impossible to obtain through classical techniques, i.e., perturbation of an almost complex structure. As a consequence, the nodal strata may have dimension larger than expected—indeed, larger than the dimension of the top stratum. This situation is a fundamental obstacle to the rigorous definition of a Gromov–Witten invariant; after all, for dimension reasons, any (nonzero) contribution to the intersection number from such a nodal stratum with large dimension would no longer be finite.\nThe pseudocycle approach to defining Gromov–Witten invariants deals with this difficulty by imposing strict conditions on the symplectic manifold which disallows such phenomena in the nodal strata. The “semipositive” condition was first introduced by McDuff in 1991 in (McDuff 1991): a symplectic manifold \\((M^{2n},\\omega)\\) is called semipositive if, for every \\(A\\in \\pi_2(M)\\),\n\\[\n    \\omega(A) &gt;0,\\ c_1(A) \\geq 3-n \\quad \\implies \\quad c_1(A) \\geq 0.\n\\]\nThis condition may seem ad-hoc, but it is specifically designed to guarantee that in the genus-zero case, the strata of nodal \\(J\\)-curves will have codimension at least \\(2\\) relative to the dimension of the top stratum of non-noded simple \\(J\\)-curves.\nTheorem. (McDuff and Salamon 2012, Thms. 6.6.1, 6.7.1) Let \\((M,\\omega)\\) be a semipositive sympletic manifold. There exists a regular almost complex structure on \\(M\\) such that the evaluation map from the genus-zero Gromov–Witten moduli space to the product \\(M\\times \\cdots \\times M,\\)\n\\[\n    ev: \\bar{\\mathcal{M}}_{A,0,k}(J) \\to M\\times\\cdots\\times M,\n\\]\nis a pseudocycle.\nThe pseudocycle Gromov–Witten invariant is the homomorphism\n\\[\n    \\text{pseudocycle-}\\mathop{\\mathrm{GW}}_{A,0,k} : H_* (M;{\\mathbb Q})^{\\otimes k} \\to {\\mathbb Q}\n\\]\ndefined via the intersection number of the pseudocycle \\(ev : {\\mathcal M}^*_{A,0,k} (J) \\to M\\times\\cdots\\times M\\) with a basis of representing submanifolds \\({\\mathcal X}\\subset M\\):\n\\[\n    \\text{pseudocycle-}\\mathop{\\mathrm{GW}}_{A,0,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k]) :=\n    ev({{\\mathcal M}^*_{A,0,k}(J)}) \\cdot \\left({\\mathcal X}_1 \\times\\cdots\\times {\\mathcal X}_k \\right).\n\\]\nThe invariant does not depend on the choice of regular almost complex structure \\(J\\), nor on the choice of representing basis.",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#the-polyfold-gromovwitten-invariant",
    "href": "mathematics.html#the-polyfold-gromovwitten-invariant",
    "title": "Mathematics",
    "section": "The polyfold Gromov–Witten invariant",
    "text": "The polyfold Gromov–Witten invariant\nPolyfold theory, developed by Hofer, Wysocki, and Zehnder, is a modern approach to resolving transversality issues that arise in attempts to solve moduli space problems in symplectic geometry. The polyfold theoretic approach to solving a moduli space problem is to recast the problem into familiar terms from differential geometry. To do this, we may construct a “Gromov–Witten polyfold” \\({\\mathcal Z}_{A,g,k}\\)—a massive, infinite-dimensional ambient space, designed to contain the entire unperturbed Gromov–Witten moduli space \\(\\bar{\\mathcal{M}}_{A,g,k}(J)\\) as a compact subset. We may furthermore construct a “strong polyfold bundle” \\({\\mathcal W}_{A,g,k}\\) over \\({\\mathcal Z}_{A,g,k}\\); the Cauchy–Riemann operator then defines a “scale smooth Fredholm section” of this bundle, \\(\\bar{\\partial}_J:{\\mathcal Z}_{A,g,k} \\to {\\mathcal W}_{A,g,k}\\), such that \\(\\smash{\\bar{\\partial}_J}\\vphantom{\\partial}^{-1}(0) = \\bar{\\mathcal{M}}_{A,g,k}(J)\\). We can construct “abstract perturbations” \\(p\\) of this section such that \\(\\bar{\\partial}_J+p\\) is transverse to the zero section and such that \\((\\bar{\\partial}_J+p)^{-1}(0)\\) is a compact set. In this way, we may take a scale smooth Fredholm section and “regularize” the unperturbed Gromov–Witten moduli space yielding a perturbed Gromov–Witten moduli space \\({\\mathcal S}_{A,g,k}(p):= (\\bar{\\partial}_J+p)^{-1}(0)\\) which has the structure of a compact oriented “weighted branched orbifold”.\n\\[\n        \\begin{array}{c}\n        \\bar{\\mathcal{M}}_{A,g,k}(J) = \\bar{\\partial}_J^{-1}(0)        \\\\\n        \\text{\\small{compact topological space}} \\\\\n        \\end{array}\n        \\xrightarrow{\\text{``polyfold regularization''}}\n        \\begin{array}{c}\n            {\\mathcal S}_{A,g,k}(p):=(\\bar{\\partial}_J+p)^{-1}(0) \\\\\n            \\text{\\small{compact ``weighted branched orbifold''}}\n        \\end{array}\n\\]\nThis approach has been successful in giving a well-defined Gromov–Witten invariant for curves of arbitrary genus, and for all closed symplectic manifolds.\nConsider homology classes \\(\\alpha_1,\\ldots, \\alpha_k \\in H_* (M;{\\mathbb Q})\\) and \\(\\beta\\in H_* (\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k};{\\mathbb Q})\\). We can represent the Poincar'e duals of the \\(\\alpha_i\\) and \\(\\beta\\) by closed differential forms in the de Rahm cohomology groups, \\(\\mathop{\\mathrm{PD}}(\\alpha_i)\\in H^*_{\\mathop{\\mathrm{dR}}} (M)\\) and \\(\\mathop{\\mathrm{PD}}(\\beta)\\in H^*_{\\mathop{\\mathrm{dR}}}(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k})\\). By pulling back via the evaluation and projection maps, we obtain a closed \\(\\text{sc}\\)-smooth differential form\n\\[\n    ev_1^* \\mathop{\\mathrm{PD}}(\\alpha_1) \\wedge \\cdots \\wedge ev_k^* \\mathop{\\mathrm{PD}}(\\alpha_k) \\wedge\\pi^* \\mathop{\\mathrm{PD}}(\\beta) \\in H^*_{\\mathop{\\mathrm{dR}}} ({\\mathcal Z}_{A,g,k}).\n\\]\nTheorem. (Hofer, Wysocki, and Zehnder 2017a, Thm. 1.12) The polyfold Gromov–Witten invariant is the homomorphism\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} : H_* (M;{\\mathbb Q})^{\\otimes k} \\otimes H_* (\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}; {\\mathbb Q}) \\to {\\mathbb Q}\n\\]\ndefined via the “branched integration” of (Hofer, Wysocki, and Zehnder 2010a):\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k;\\beta) : = \\int_{{\\mathcal S}_{A,g,k}(p)} ev_1^* \\mathop{\\mathrm{PD}}(\\alpha_1) \\wedge \\cdots \\wedge ev_k^* \\mathop{\\mathrm{PD}}(\\alpha_k) \\wedge\\pi^* \\mathop{\\mathrm{PD}}(\\beta).\n\\]\nThis invariant does not depend on the choice of perturbation.",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#orbifolds-and-the-steenrod-problem",
    "href": "mathematics.html#orbifolds-and-the-steenrod-problem",
    "title": "Mathematics",
    "section": "Orbifolds and the Steenrod problem",
    "text": "Orbifolds and the Steenrod problem\nThe Steenrod problem was first presented in (Eilenberg 1949) and asked the following question:\n\nCan any homology class of a finite polyhedron be represented as an image of the fundamental class of some manifold?\n\nIn (Thom 1954) Thom conclusively answered this problem, completely solving it for closed orientable manifolds.\nTheorem (Thom 1954, Thm II.1) The rational homology groups of a closed orientable manifold have a basis consisting of classes represented by closed embedded submanifolds.\nFor solving this problem, and for his related work inventing cobordism theory, Thom was awarded the Fields medal in 1958. Aided by the modern language of ep-groupoids, I was able to follow the same approach as Thom and obtain the following analogue for orbifolds.\nTheorem (Schmaltz 2019a, The Steenrod problem for orbifolds) The rational homology groups of a closed orientable orbifold have a basis consisting of classes represented by “closed embedded full suborbifolds whose normal bundles have fiberwise trivial isotropy action”.\nIn other words, given a closed orientable orbifold \\(\\mathcal{O}\\) there exists a basis \\(\\{[\\mathcal{X}_i]\\}\\) of the rational homology groups \\(H_*(\\mathcal{O};\\mathbb{Q})\\) which consists of the fundamental classes of such “closed embedded full suborbifolds \\(\\mathcal{X}_i\\subset \\mathcal{O}\\) whose normal bundles have fiberwise trivial isotropy action”. Such a suborbifold is called a representing suborbifold.\nRepresenting suborbifolds are well-suited for general intersection theories. Given such a suborbifold, the underlying topological space of the normal bundle is a vector bundle over the underlying topological space of the suborbifold. In contrast, the underlying topological space of an arbitrary orbifold bundle will generally not be a vector bundle. This means it is possible to use single valued sections (as opposed to multisections) for arguments involving perturbations.\n\n\n\nThe Steenrod problem for orbifolds",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#polyfold-gromovwitten-invariants-as-intersection-numbers",
    "href": "mathematics.html#polyfold-gromovwitten-invariants-as-intersection-numbers",
    "title": "Mathematics",
    "section": "Polyfold Gromov–Witten invariants as intersection numbers",
    "text": "Polyfold Gromov–Witten invariants as intersection numbers\nThe earliest interpretations of the Gromov–Witten invariants present in the literature were given in terms of counting a finite number of curves (McDuff and Salamon 2012; Ruan 1994, 1996). For example, Ruan described the Gromov–Witten invariants as a finite sum, counted with multiplicity, of nonmultiple cover \\(J\\)-spheres in \\({\\mathcal M}^*_{(A,J)}\\) which intersect representatives of given cycles in the symplectic manifold (Ruan 1996, Thm. A).\nHowever, such definitions have previously been restricted to genus zero Gromov–Witten invariants in semipositive symplectic manifolds. Observe that in the genus \\(0\\) case the Grothendieck–Knudsen spaces \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{0,k}\\) are finite-dimensional manifolds. In contrast, if genus \\(g &gt;0\\) the general Deligne–Mumford spaces \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) are orbifolds. Therefore, in the genus \\(0\\) case extant methods—such as representing a homology class as a pseudocycle in a manifold or, indeed, the Steenrod problem for manifolds—were sufficient to interpret the Gromov–Witten invariants as an intersection number.\nUsing the Steenrod problem for orbifolds, I was able to prove that the polyfold Gromov–Witten invariants may equivalently be defined as an intersection number. Let \\({\\mathcal S}_{A,g,k}(p)\\) be a perturbed Gromov–Witten moduli space, and let \\({\\mathcal X}_1\\times \\cdots \\times {\\mathcal X}_k \\times {\\mathcal B}\\) be a representing suborbifold of \\(M^k \\times \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\).\nI showed that transversality of a perturbed solution space of a polyfold with a representing submanifolds/suborbifolds may always be achieved through either of the following:\n\nThrough the perturbation of the representing suborbifold; due to the properties of the normal bundle representing suborbifolds may always be perturbed (Schmaltz 2019a, Prop. 3.9).\nAssuming the map defined on the ambient polyfold is a submersion, we may obtain transversality through choice of a suitable abstract perturbation (Schmaltz 2019a, Prop. 3.10).\n\nWhen \\(\\dim {\\mathcal S}_{A,g,k}(p) + \\dim \\left({\\mathcal X}_1 \\times\\cdots\\times {\\mathcal X}_k \\times {\\mathcal B}\\right) = \\dim (M^k \\times \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k})\\) the intersection number is given by the signed weighted count of a finite number of points of intersection.\nTheorem (Schmaltz 2019a, Polyfold Gromov–Witten invariants as intersection numbers) The polyfold Gromov–Witten invariant may equivalently be defined as the intersection number evaluated on a basis of representing submanifolds \\({\\mathcal X}\\subset M\\) and representing suborbifolds \\({\\mathcal B}\\subset {\\mathcal O}\\):\n\\[\n    \\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) :=\n    \\left(ev_1\\times\\cdots\\times ev_k\\times\\pi\\right)|_{{\\mathcal S}_{A,g,k}(p)} \\cdot \\left({\\mathcal X}_1 \\times\\cdots\\times {\\mathcal X}_k \\times {\\mathcal B}\\right).\n\\]\nThe invariant does not depend on the choice of abstract perturbation, nor on the choice of representing basis.\nThus the traditional geometric interpretation of the Gromov–Witten invariants as a “count of curves” is made literal.\n\n\n\nA Gromov–Witten invariant",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#a-polyfold-proof-of-the-gromovwitten-axioms",
    "href": "mathematics.html#a-polyfold-proof-of-the-gromovwitten-axioms",
    "title": "Mathematics",
    "section": "A polyfold proof of the Gromov–Witten axioms",
    "text": "A polyfold proof of the Gromov–Witten axioms\nIn 2019, I succeeded in giving a complete proof of the Gromov–Witten axioms.\nTheorem (Schmaltz 2019c, Polyfold Gromov–Witten axioms) The polyfold Gromov–Witten invariants satisfy the Gromov–Witten axioms:\nEffective axiom. If \\(\\omega(A)&lt;0\\) then \\(\\mathop{\\mathrm{GW}}_{A,g,k} = 0\\).\nGrading axiom. If \\(\\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\beta) \\neq 0\\) then\n\\[\n    \\sum_{i=1}^k (2n - \\deg (\\alpha_i)) + (6g-6+2k - \\deg(\\beta)) = 2c_1(A) + (2n - 6)(1-g) + 2k.\n\\]\nHomology axiom. There exists a homology class\n\\[\n        \\sigma_{A,g,k} \\in H_{2c_1(A) + (2n-6)(1-g) + 2k} (M^k\\times \\bar{\\mathcal{M}}_{g,k};{\\mathbb Q})\n\\]\nsuch that\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\beta) = \\langle p_1^* \\mathop{\\mathrm{PD}}(\\alpha_1) \\smallsmile \\cdots \\smallsmile p_k^*\\mathop{\\mathrm{PD}}(\\alpha_k) \\smallsmile p_0^*\\mathop{\\mathrm{PD}}(\\beta), \\sigma_{A,g,k} \\rangle\n\\]\nwhere \\(p_i: M^k \\times \\bar{\\mathcal{M}}_{g,k} \\to M\\) denotes the projection onto the \\(i\\)th factor and the map \\(p_0:M^k \\times \\bar{\\mathcal{M}}_{g,k}\\to\\bar{\\mathcal{M}}_{g,k}\\) denotes the projection onto the last factor.\nZero axiom. If \\(A=0,\\ g=0\\) then \\(\\mathop{\\mathrm{GW}}_{0,0,k} (\\alpha_1,\\ldots,\\alpha_k;\\beta) = 0\\) whenever \\(\\deg (\\beta) &gt;0\\), and\n\\[\n        \\mathop{\\mathrm{GW}}_{0,0,k} (\\alpha_1,\\ldots,\\alpha_k; [\\operatorname{pt}]) = \\int_M \\mathop{\\mathrm{PD}}(\\alpha_1) \\wedge \\cdots \\wedge \\mathop{\\mathrm{PD}}(\\alpha_k).\n\\]\nSymmetry axiom. Fix a permutation \\(\\sigma: \\{1,\\ldots, k\\}\\to \\{1,\\ldots,k\\}\\). Consider the permutation map \\(\\sigma:\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}, \\ [\\Sigma,j,M,D]  \\mapsto [\\Sigma,j,M^\\sigma,D]\\) where \\(M = \\{z_1,\\ldots,z_k\\}\\) and where \\(M^\\sigma := \\{z'_1,\\ldots,z'_k\\},\\) \\(z'_i:= z_{\\sigma(i)}\\). Then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_{\\sigma(1)},\\ldots,\\alpha_{\\sigma(k)}; \\sigma_*\\beta) = (-1)^{N(\\sigma;\\alpha_i)} \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\beta)\n\\]\nwhere \\(N(\\sigma;\\alpha_i):= \\sharp    \\{  i&lt;j \\mid \\sigma(i)&gt; \\sigma(j), \\deg (\\alpha_i)\\deg(\\alpha_j)\\in 2{\\mathbb Z}+1\\}\\).\nDefinition. (Kontsevich and Manin 1994, Eq. 2.3) We say that \\((A,g,k)\\) is a basic class if it is equal to one of the following: \\((A,0,3)\\), \\((A,1,1)\\), or \\((A,g\\geq 2,0)\\).\nThe point is, for such values of \\(g\\) and \\(k\\) we will have \\(\\bar{\\mathcal{M}}_{g,k-1} = \\emptyset\\) by definition.\nFundamental class axiom. Consider the fundamental classes \\([M]\\in H_{2n}(M;{\\mathbb Q})\\) and \\([\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}] \\in H_{6g-6+2k}(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k};{\\mathbb Q})\\). Suppose that \\(A\\neq 0\\) and that \\((A,g,k)\\) is not basic. Then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_{k-1},[M]; [\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}]) = 0.\n\\]\nConsider the canonical section \\(s_i :\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k-1} \\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) defined by doubling the \\(i\\)th-marked point. Then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_{k-1},[M]; s_{i*}\\beta) = \\mathop{\\mathrm{GW}}_{A,g,k-1} (\\alpha_1,\\ldots,\\alpha_{k-1};\\beta).\n\\]\nDivisor axiom. Suppose \\((A,g,k)\\) is not basic. If \\(\\deg (\\alpha_k) = 2n-2\\) then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\mathop{\\mathrm{PD}}(ft_k^* \\mathop{\\mathrm{PD}}(\\beta))) = (A\\cdot \\alpha_k ) \\ \\mathop{\\mathrm{GW}}_{A,g,k-1} (\\alpha_1,\\ldots,\\alpha_{k-1};\\beta),\n\\]\nwhere \\(A\\cdot \\alpha_k\\) is given by the homological intersection product.\nLet \\(\\{e_\\nu \\} \\in H^*(M;{\\mathbb Q})\\) be a homogeneous basis and let \\(\\{e^\\mu \\} \\in H^*(M;{\\mathbb Q})\\) be the dual basis with respect to Poincaré duality, i.e., \\(\\langle e_\\nu \\smallsmile e^\\mu, [M] \\rangle = \\delta_{\\nu \\mu}\\). It follows from the Künneth formula that \\(\\{e_\\nu \\otimes e^\\mu \\}\\) is a basis for \\(H^*(M\\times M;{\\mathbb Q})\\). We correct the sign by redefining \\(e_\\nu\\) as \\((-1)^{\\deg e_\\nu} e_\\nu\\). We can write the Poincaré dual of the diagonal \\(\\Delta \\subset M\\times M\\) in this basis as \\(\\mathop{\\mathrm{PD}}([\\Delta]) = \\sum_\\nu e_\\nu \\otimes e^\\nu\\).\nSplitting axiom. Fix a partition \\(S_0 \\sqcup S_1 =\\{1,\\ldots, k\\}\\). Let \\(k_0 := \\sharp S_0\\), \\(k_1 := \\sharp S_1\\) and let \\(g_0\\), \\(g_1 \\geq 0\\) such that \\(g = g_0 + g_1\\), and \\(k_i + g_i \\geq 2\\) for \\(i=0,1\\). Consider the natural map \\[\\phi_S : \\bar{\\mathcal{M}}_{k_0+1 , g_0}\\times \\bar{\\mathcal{M}}_{k_1+1 , g_1} \\to \\bar{\\mathcal{M}}_{g,k}\\] which identifies the last marked point of a stable noded Riemann surface in \\(\\bar{\\mathcal{M}}_{k_0+1 , g_0}\\) with the first marked point of a stable noded Riemann surface in \\(\\bar{\\mathcal{M}}_{k_1+1, g_1}\\), and which maps the first \\(k_0\\) marked points of \\(\\bar{\\mathcal{M}}_{g_0,k_0+1}\\) to marked points indexed by \\(S_0\\) and likewise maps the last \\(k_1\\) marked points of \\(\\bar{\\mathcal{M}}_{g_1,k_1+1}\\) to marked points indexed by \\(S_1\\). Then\n\\[\n    \\begin{align*}\n         & \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1, \\ldots, \\alpha_k; \\phi_{S*} (\\beta_0\\otimes \\beta_1) ) =\n        (-1)^{N(S;\\alpha)} \\sum_{A_0+A_1 = A}   \\sum_\\nu                                     \\\\\n         & \\qquad\n        \\mathop{\\mathrm{GW}}_{A_0,g_0,k_0+1} (\\{\\alpha_i\\}_{i\\in S_0}, \\mathop{\\mathrm{PD}}(e_\\nu) ; \\beta_0)\n        \\cdot\n        \\mathop{\\mathrm{GW}}_{A_1,g_1,k_1+1} (\\mathop{\\mathrm{PD}}(e^\\nu), \\{\\alpha_j\\}_{j\\in S_1} ; \\beta_1)\n    \\end{align*}\n\\]\nwhere \\(N(S;\\alpha)=\\sharp \\{j&lt;i \\mid i\\in S_0, j\\in S_1, \\deg(\\alpha_i)\\deg(\\alpha_j)\\in 2{\\mathbb Z}+1 \\}\\).\nGenus reduction axiom. Consider the natural map \\[\\psi: \\bar{\\mathcal{M}}_{g-1,k+2} \\to \\bar{\\mathcal{M}}_{g,k}\\] which identifies the last two marked points of a stable noded Riemann surface, increasing the arithmetic genus by one. Then\n\\[\n  2 \\cdot \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1, \\ldots, \\alpha_k; \\psi_* \\beta) = \\sum_\\nu \\mathop{\\mathrm{GW}}_{A,g-1,k+2} (\\alpha_1,\\ldots,\\alpha_k, \\mathop{\\mathrm{PD}}(e_\\nu) , \\mathop{\\mathrm{PD}}(e^\\nu) ; \\beta).\n\\]",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#strategy-of-the-proof-of-the-gromovwitten-axioms",
    "href": "mathematics.html#strategy-of-the-proof-of-the-gromovwitten-axioms",
    "title": "Mathematics",
    "section": "Strategy of the proof of the Gromov–Witten axioms",
    "text": "Strategy of the proof of the Gromov–Witten axioms\nThe Gromov–Witten axioms give relationships between the Gromov–Witten invariants. These relationships are determined by the geometry of certain naturally defined maps defined between the unperturbed Gromov–Witten moduli spaces, namely:\n\npermutation maps, \\[\\sigma : \\bar{\\mathcal{M}}_{A,g,k}(J) \\to \\bar{\\mathcal{M}}_{A,g,k}(J),\\]\n\\(k\\)th-marked point forgetting maps, \\[ft_k : \\bar{\\mathcal{M}}_{A,g,k}(J) \\to \\bar{\\mathcal{M}}_{A,g,k-1}(J),\\]\ncanonical sections, \\[s_i : \\bar{\\mathcal{M}}_{A,g,k-1}(J) \\hookrightarrow \\bar{\\mathcal{M}}_{A,g,k}(J).\\]\n\nFurthermore, using the map\n\\[\n    ev_{k_0+1} \\times ev_1 : \\bar{\\mathcal{M}}_{A_0,g_0,k_0+1}(J) \\times \\bar{\\mathcal{M}}_{A_1,g_1,k_1+1}(J) \\to M\\times M\n\\]\nwe may consider the subset \\((ev_{k_0+1} \\times ev_1 )^{-1}(\\Delta)\\) of the product unperturbed Gromov–Witten moduli space with a constraint imposed by the diagonal \\(\\Delta \\subset M\\times M\\). We then additionally have:\n\ninclusion maps, and maps \\(\\phi\\) which identify the marked points \\(z_{k_0+1}\\) and \\(z_1'\\), \\[\n  \\begin{align*}\n      \\bar{\\mathcal{M}}_{A_0,g_0,k_0+1}(J) & \\times \\bar{\\mathcal{M}}_{A_1,g_1,k_1+1}(J) \\\\\n      i \\bigg{\\uparrow} & \\\\\n      (ev_{k_0+1} & \\times ev_1 )^{-1}(\\Delta) \\xrightarrow{\\phi} \\bar{\\mathcal{M}}_{A_0+A_1,g_0+g_1,k_0+k_1}(J)\n  \\end{align*}\n\\] Likewise, using the map \\(ev_{k+1} \\times ev_{k+2} : \\bar{\\mathcal{M}}_{A,g-1,k+2}(J) \\to M\\times M\\) we may consider the subset \\((ev_{k+1} \\times ev_{k+2} )^{-1}(\\Delta)\\) of the unperturbed Gromov–Witten moduli space with a constraint imposed by the diagonal \\(\\Delta \\subset M\\times M\\). We then additionally have:\ninclusion maps, and maps \\(\\psi\\) which identify the marked points \\(z_{k+1}\\) and \\(z_{k+2}\\) (increasing the arithmetic genus by one), \\[\n  \\begin{align*}\n      \\bar{\\mathcal{M}}_{A,g-1,k+2}& (J)    \\\\\n      i \\bigg{\\uparrow} \\qquad &\\\\\n      (ev_{k+1} \\times ev_{k+2}& )^{-1}(\\Delta) \\xrightarrow{\\psi} \\bar{\\mathcal{M}}_{A,g,k}(J)\n  \\end{align*}\n\\]\n\nIntuitively, we should prove the Gromov–Witten axioms by interpreting the Gromov–Witten invariants as a finite count of curves and using the geometry of the above maps to directly compare such counts with respect to constraints imposed by the homology classes on \\(M\\) and \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\).\nA substantial amount of work is required to make this intuition rigorous in the context of an abstract perturbation theory. A deep understanding of the full machinery of polyfold theory, in addition to the geometry of the Gromov–Witten invariants is necessary to navigate substantial difficulties that we encounter.",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#difficulties-in-proving-the-polyfold-gromovwitten-axioms",
    "href": "mathematics.html#difficulties-in-proving-the-polyfold-gromovwitten-axioms",
    "title": "Mathematics",
    "section": "Difficulties in proving the polyfold Gromov–Witten axioms",
    "text": "Difficulties in proving the polyfold Gromov–Witten axioms\nProving this required a substantial amount of work, and relied on the results of (Schmaltz 2019b, 2019a). The Gromov–Witten axioms give relationships between the Gromov–Witten invariants. These relationships are determined by the geometry of certain naturally defined maps defined between the unperturbed Gromov–Witten moduli spaces, namely the permutation maps, the \\(k\\)th-marked point forgetting maps, in addition to certain natural maps which identify marked points into nodal pairs, where the Gromov–Witten moduli space is subject to a diagonal constraint. With the exception of the \\(k\\)th-marked point forgetting maps, we may pullback abstract perturbations in order to obtain well-defined restricted maps between perturbed Gromov–Witten moduli spaces.\nThe branched integral is useful for giving a well-defined definition of the polyfold Gromov–Witten invariants and moreover showing that they are, in fact, invariants and do not depend on choices. But integration is not the best viewpoint for giving a proof of all of the axioms. Intuitively, we should prove the Gromov–Witten axioms by interpreting the Gromov–Witten invariants as an intersection number and using the geometry of the above maps to directly compare such counts with respect to constraints imposed by the homology classes on \\(M\\) and \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\). And indeed, via (Schmaltz 2019a) this intuition is made rigorous, and is precisely my approach to proving the axioms.\nHowever, problems arise when we try to define a \\(k\\)th-marked point forgetting map between perturbed Gromov–Witten moduli spaces—such a map does not even exist. The construction of the smooth structure for the Deligne–Mumford orbifolds as described in (Hofer, Wysocki, and Zehnder 2017a) and (Hofer, Wysocki, and Zehnder, n.d.) requires a choice: that of a “gluing profile,” i.e., a smooth diffeomorphism \\(\\varphi: (0,1]\\to [0,\\infty).\\) Given a noded Riemann surface and a nonzero parameter \\(a \\in {\\mathbb C}\\) we use the gluing profile to replace a region of the node with a cylinder of finite length \\(\\varphi(\\lvert a\\rvert)\\). The logarithmic gluing profile is given by \\(\\varphi_{\\log} (r) = -\\frac{1}{2\\pi} \\log (r)\\) and produces the classical holomorphic Deligne–Mumford orbifolds \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\). There is also an exponential gluing profile, given by \\(\\varphi_{\\exp} (r) = e^{1/r} - e\\) which produces Deligne–Mumford orbifolds \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{exp}}_{g,k}\\) which are only smooth orbifolds. The exponential gluing profile is required for the scale smoothness of certain maps used to define the Gromov–Witten polyfolds.\nThis use of nonstandard smooth structure has the following consequence:\n\nProblem 1. In general the map \\(ft_k: \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{exp}}_{g,k} \\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{exp}}_{g,k-1}\\) is continuous but not differentiable.\n\nIndependent of the usage of a nonstandard gluing profile, there is no hope whatsoever of defining a \\(k\\)th-marked point forgetting map on the Gromov–Witten polyfolds as they are defined:\n\nProblem 2. In general there does not exist a natural map \\(ft_k\\) on the Gromov–Witten polyfolds.\n\nTo explain, a stable curve in \\({\\mathcal Z}_{A,g,k}\\) may contain a “destabilizing ghost component,” i.e., a component \\(C_k\\simeq S^2\\) with precisely \\(3\\) special points, one of which is the \\(k\\)th-marked point, and such that \\(\\int_{C_k} u^*\\omega=0,\\) \\(u|_{C_k} \\neq\\text{const}.\\) After removal of the \\(k\\)th-marked point from such a component we cannot consider the resulting data as a stable curve in \\({\\mathcal Z}_{A,g,k-1}\\).\nWe might try to restrict to a subset \\({\\mathcal Z}^\\text{const}_{A,g,k}\\subset {\\mathcal Z}_{A,g,k}\\) consisting of stable curves which are constant on such destabilizing ghost components. The \\(k\\)th-marked point forgetting map is then well-defined on this subset. However, if we consider \\(\\mathcal{Z}^\\text{const}_{A,g,k}\\subset \\mathcal{Z}_{A,g,k}\\) with the subspace topology, and \\(\\mathcal{Z}_{A,g,k-1}\\) with the usual polyfold topology, then:\n\nProblem 3. In general the well-defined restriction \\(ft_k:{\\mathcal Z}_{A,g,k}^\\text{const} \\to \\mathcal{Z}_{A,g,k-1}\\) is not continuous.\n\nThere is a final problem. In general, the projection map must factor through the \\(k\\)th-marked point forgetting map; this is due to the need to forget the added stabilizing points. Thus, in order to obtain a smooth projection map we must map to the logarithmic Deligne–Mumford orbifold. However:\n\nProblem 4. While the projection \\(\\pi : {\\mathcal Z}_{A,g,k} \\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) is \\(\\text{sc}\\)-smooth, in general it is not a submersion.\n\nThis has important consequences if we wish to consider the Gromov–Witten invariant as an intersection number; the only way to get transversality of the projection map with a representing suborbifold \\({\\mathcal B}\\subset \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) is through perturbation of the suborbifold. This is made possible by the existence of representing suborbifolds, for which perturbation is possible, the existence of which is guaranteed by (Schmaltz 2019a).",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#the-universal-curve-gromovwitten-polyfold",
    "href": "mathematics.html#the-universal-curve-gromovwitten-polyfold",
    "title": "Mathematics",
    "section": "The universal curve Gromov–Witten polyfold",
    "text": "The universal curve Gromov–Witten polyfold\nIn essence, the central problem is that the Gromov–Witten polyfolds as constructed are not “universal curves”. My proof of the Gromov–Witten axioms rectifies this by constructing a universal curve polyfold \\({\\mathcal Z}^\\text{uc}_{A,g,k}\\) over \\({\\mathcal Z}_{A,g,k-1}\\), on which we may consider a well-defined \\(k\\)th-marked point forgetting map\n\\[\n    ft_k : {\\mathcal Z}^\\text{uc}_{A,g,k} \\to {\\mathcal Z}_{A,g,k-1}.\n\\]\nThe preimage of stable curve in \\({\\mathcal Z}_{A,g,k-1}\\) via \\(ft_k\\) can be identified with the underlying Riemann surface with nodes identified, thereby explaining the choice of nomenclature “universal curve”. It is possible to pullback regular perturbations via this map, and hence obtain a well-defined map between perturbed Gromov–Witten moduli spaces.\nNow we find ourselves in the following situation: given the Gromov–Witten moduli space \\(\\bar{\\mathcal{M}}_{A,g,k}\\) we can define polyfold Gromov–Witten invariants associated to the usual Gromov–Witten polyfold \\({\\mathcal Z}_{A,g,k}\\) and associated to the universal curve polyfold \\({\\mathcal Z}^\\text{uc}_{A,g,k}\\) which, a priori, we cannot assume are equivalent.\nIn (Schmaltz 2019b), I present a general framework for proving that polyfold invariants are natural, which applied to polyfold Gromov–Witten theory yields the following result.\nTheorem. (Schmaltz 2019b, Naturality of the polyfold Gromov–Witten invariants) The polyfold Gromov–Witten invariants are natural, and do not depend on auxiliary choices made in their construction. In particular, the Gromov–Witten invariants associated to the usual Gromov–Witten polyfold and associated to the universal curve Gromov–Witten polyfold are identical.",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "mathematics.html#pseudocycle-gromovwitten-invariants-are-a-strict-subset-of-polyfold-gromovwitten-invariants",
    "href": "mathematics.html#pseudocycle-gromovwitten-invariants-are-a-strict-subset-of-polyfold-gromovwitten-invariants",
    "title": "Mathematics",
    "section": "Pseudocycle Gromov–Witten invariants are a strict subset of polyfold Gromov–Witten invariants",
    "text": "Pseudocycle Gromov–Witten invariants are a strict subset of polyfold Gromov–Witten invariants\nI unified the classical definition of a Gromov–Witten invariant as a pseudocycle and the modern definition of a Gromov–Witten invariant via polyfold theory by proving they are equivalent.\nTheorem. (Schmaltz 2023, Main result) For a given semipositive symplectic manifold, the pseudocycle genus-zero Gromov–Witten invariants are equal to the polyfold genus-zero Gromov–Witten invariants.\nSince the polyfold Gromov–Witten invariants are not restricted to genus-zero, nor to semipositive symplectic manifolds, we have\n\\[\n    \\left\\{ \\begin{array}{c} \\textit{pseudocycle} \\\\ \\textit{Gromov-Witten} \\\\ \\textit{invariants} \\end{array} \\right\\}\n    \\subsetneq\n    \\left\\{ \\begin{array}{c} \\textit{polyfold} \\\\ \\textit{Gromov-Witten} \\\\ \\textit{invariants} \\end{array} \\right\\}.\n\\]\n\nReferences\n\n\nCastellano, Robert. 2016. Kuranishi Atlases and Genus Zero Gromov–Witten Invariants. ProQuest LLC, Ann Arbor, MI. http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:10096865 .\n\n\nCieliebak, Kai, and Klaus Mohnke. 2007. “Symplectic Hypersurfaces and Transversality in Gromov–Witten Theory.” J. Symplectic Geom. 5 (3): 281–356. http://projecteuclid.org/euclid.jsg/1210083200.\n\n\nEilenberg, Samuel. 1949. “On the Problems of Topology.” Ann. Of Math. (2) 50: 247–60. https://doi.org/10.2307/1969448.\n\n\nFabert, Oliver, Joel W. Fish, Roman Golovko, and Katrin Wehrheim. 2016. “Polyfolds: A First and Second Look.” EMS Surv. Math. Sci. 3 (2): 131–208. https://doi.org/10.4171/EMSS/16.\n\n\nFloer, Andreas. 1988. “An Instanton-Invariant for \\(3\\)-Manifolds.” Comm. Math. Phys. 118 (2): 215–40. http://projecteuclid.org/euclid.cmp/1104161987.\n\n\nFukaya, Kenji, Yong-Geun Oh, Hiroshi Ohta, and Kaoru Ono. 2012. “Technical details on Kuranishi structure and virtual fundamental chain.” arXiv e-Prints. September 2012. https://arxiv.org/abs/1209.4410.\n\n\nFukaya, Kenji, and Kaoru Ono. 1999. “Arnold Conjecture and Gromov–Witten Invariant for General Symplectic Manifolds.” In The Arnoldfest (Toronto, ON, 1997), 24:173–90. Fields Inst. Commun. Amer. Math. Soc., Providence, RI.\n\n\nGromov, M. 1985. “Pseudo Holomorphic Curves in Symplectic Manifolds.” Invent. Math. 82 (2): 307–47. https://doi.org/10.1007/BF01388806.\n\n\nHofer, Helmut, Kris Wysocki, and Eduard Zehnder. 2007. “A General Fredholm Theory. I. A Splicing-Based Differential Geometry.” J. Eur. Math. Soc. (JEMS) 9 (4): 841–76. https://doi.org/10.4171/JEMS/99.\n\n\n———. 2009a. “A General Fredholm Theory. II. Implicit Function Theorems.” Geom. Funct. Anal. 19 (1): 206–93. https://doi.org/10.1007/s00039-009-0715-x.\n\n\n———. 2009b. “A General Fredholm Theory. III. Fredholm Functors and Polyfolds.” Geom. Topol. 13 (4): 2279–2387. https://doi.org/10.2140/gt.2009.13.2279.\n\n\n———. 2010a. “Integration Theory on the Zero Sets of Polyfold Fredholm Sections.” Math. Ann. 346 (1): 139–98. https://doi.org/10.1007/s00208-009-0393-x.\n\n\n———. 2010b. “Sc-Smoothness, Retractions and New Models for Smooth Spaces.” Discrete Contin. Dyn. Syst. 28 (2): 665–788. https://doi.org/10.3934/dcds.2010.28.665.\n\n\n———. 2017a. “Applications of Polyfold Theory I: The Polyfolds of Gromov– Witten Theory.” Mem. Amer. Math. Soc. 248 (1179): v+218. https://doi.org/10.1090/memo/1179.\n\n\n———. 2017b. “Polyfold and Fredholm theory.” arXiv e-Prints. July 2017. https://arxiv.org/abs/1707.08941.\n\n\n———. n.d. “Deligne–Mumford-Type Spaces with a View Towards Symplectic Field Theory.”\n\n\nIonel, Eleny-Nicoleta, and Thomas H. Parker. 2013. “A natural Gromov–Witten virtual fundamental class.” arXiv e-Prints. February 2013. https://arxiv.org/abs/1302.3472.\n\n\nKontsevich, Maxim. 1995. “Enumeration of Rational Curves via Torus Actions.” In The Moduli Space of Curves (Texel Island, 1994), 129:335–68. Progr. Math. Birkhäuser Boston, Boston, MA. https://doi.org/10.1007/978-1-4612-4264-2_12.\n\n\nKontsevich, Maxim, and Yuri Manin. 1994. “Gromov–Witten Classes, Quantum Cohomology, and Enumerative Geometry.” Comm. Math. Phys. 164 (3): 525–62. http://projecteuclid.org/euclid.cmp/1104270948.\n\n\nLi, Jun, and Gang Tian. 1998. “Virtual Moduli Cycles and Gromov–Witten Invariants of General Symplectic Manifolds.” In Topics in Symplectic \\(4\\)-Manifolds (Irvine, CA, 1996), 47–83. First Int. Press Lect. Ser., i. Int. Press, Cambridge, MA.\n\n\nMcDuff, Dusa. 1991. “Symplectic Manifolds with Contact Type Boundaries.” Invent. Math. 103 (3): 651–71. https://doi.org/10.1007/BF01239530.\n\n\nMcDuff, Dusa, and Dietmar Salamon. 2012. \\(J\\)-Holomorphic Curves and Symplectic Topology. Second. Vol. 52. American Mathematical Society Colloquium Publications. American Mathematical Society, Providence, RI.\n\n\nMcDuff, Dusa, and Katrin Wehrheim. 2012. “Kuranishi atlases with trivial isotropy - the 2013 state of affairs.” arXiv e-Prints. August 2012. https://arxiv.org/abs/1208.1340.\n\n\n———. 2017. “The Topology of Kuranishi Atlases.” Proc. Lond. Math. Soc. (3) 115 (2): 221–92. https://doi.org/10.1112/plms.12032.\n\n\n———. 2018. “The Fundamental Class of Smooth Kuranishi Atlases with Trivial Isotropy.” J. Topol. Anal. 10 (1): 71–243. https://doi.org/10.1142/S1793525318500048.\n\n\nPardon, John. 2016. “An Algebraic Approach to Virtual Fundamental Cycles on Moduli Spaces of Pseudo-Holomorphic Curves.” Geom. Topol. 20 (2): 779–1034. https://doi.org/10.2140/gt.2016.20.779.\n\n\nRuan, Yongbin. 1994. “Symplectic Topology on Algebraic \\(3\\)-Folds.” J. Differential Geom. 39 (1): 215–27. http://projecteuclid.org/euclid.jdg/1214454682.\n\n\n———. 1996. “Topological Sigma Model and Donaldson-Type Invariants in Gromov Theory.” Duke Math. J. 83 (2): 461–500. https://doi.org/10.1215/S0012-7094-96-08316-7.\n\n\nRuan, Yongbin, and Gang Tian. 1995. “A Mathematical Theory of Quantum Cohomology.” J. Differential Geom. 42 (2): 259–367. http://projecteuclid.org/euclid.jdg/1214457234.\n\n\nSchmaltz, Wolfgang. 2019a. “The Steenrod problem for orbifolds and polyfold invariants as intersection numbers.” arXiv e-Prints. April 2019. https://arxiv.org/abs/1904.02186.\n\n\n———. 2019b. “Naturality of polyfold invariants and pulling back abstract perturbations.” arXiv e-Prints. December 2019. https://arxiv.org/abs/1912.13370.\n\n\n———. 2019c. “The Gromov–Witten axioms for symplectic manifolds via polyfold theory.” arXiv e-Prints. December 2019. https://arxiv.org/abs/1912.13374.\n\n\n———. 2023. “Pseudocycle Gromov-Witten invariants are a strict subset of polyfold Gromov-Witten invariants.” arXiv e-Prints. https://doi.org/10.48550/arXiv.2308.14204.\n\n\nSiebert, Bernd. 1996. “Gromov–Witten invariants of general symplectic manifolds.” Eprint arXiv:dg-Ga/960800. August 1996. https://arxiv.org/abs/dg-ga/9608005.\n\n\nThom, René. 1954. “Quelques Propriétés Globales Des Variétés Diffé Rentiables.” Comment. Math. Helv. 28: 17–86. https://doi.org/10.1007/BF02566923.\n\n\nWitten, Edward. 1988. “Topological Sigma Models.” Comm. Math. Phys. 118 (3): 411–49. http://projecteuclid.org/euclid.cmp/1104162092.\n\n\n———. 1991. “Two-Dimensional Gravity and Intersection Theory on Moduli Space.” In Surveys in Differential Geometry (Cambridge, MA, 1990), 243–310. Lehigh Univ., Bethlehem, PA.",
    "crumbs": [
      "Mathematics"
    ]
  },
  {
    "objectID": "limitations.html",
    "href": "limitations.html",
    "title": "Limitations of machine learning",
    "section": "",
    "text": "What are the limitations?\n\nhttps://www.nytimes.com/2023/05/16/technology/microsoft-ai-human-reasoning.html?action=click&pgtype=Article&state=default&module=styln-artificial-intelligence&variant=show&region=BELOW_MAIN_CONTENT&block=storyline_flex_guide_recirc\nhttps://ryxcommar.com/2023/03/28/chatgpt-as-a-query-engine-on-a-giant-corpus-of-text/\nhttps://www.nytimes.com/2023/07/02/science/ai-mathematics-machine-learning.html\n\nLook up other examples where ChatGPT is easily tricked and confused\nUse some examples from mathematics\nLook at Michael Hutchings facebook posts"
  },
  {
    "objectID": "mathematics-research.html",
    "href": "mathematics-research.html",
    "title": "Mathematics research",
    "section": "",
    "text": "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Standard Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%mathbb \n%greek \n%GREEK \n%cal \n%tilde \n%bar % \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Math Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%compactified moduli space \n% % % % %SYMPLECTIC GEOMETRY % % % % % \n% % % % %Hat Delbar % % % % % \n% % % % %COLORS % % % % %\n% % % % %GROMOV-WITTEN LANGUAGE % % % % % \n% % % % %THOM LANGUAGE % % % % % \n% % % % %POLYFOLD LANGUAGE % % % % %"
  },
  {
    "objectID": "mathematics-research.html#orbifolds-and-the-steenrod-problem",
    "href": "mathematics-research.html#orbifolds-and-the-steenrod-problem",
    "title": "Mathematics research",
    "section": "Orbifolds and the Steenrod problem",
    "text": "Orbifolds and the Steenrod problem\nThe Steenrod problem was first presented in (Eilenberg 1949) and asked the following question:\n\nCan any homology class of a finite polyhedron be represented as an image of the fundamental class of some manifold?\n\nIn (Thom 1954) Thom conclusively answered this problem, completely solving it for closed orientable manifolds.\nTheorem (Thom 1954, Thm II.1) The rational homology groups of a closed orientable manifold have a basis consisting of classes represented by closed embedded submanifolds.\nFor solving this problem, and for his related work inventing cobordism theory, Thom was awarded the Fields medal in 1958. Aided by the modern language of ep-groupoids, I was able to follow the same approach as Thom and obtain the following analogue for orbifolds.\nTheorem (Schmaltz 2019a, The Steenrod problem for orbifolds) The rational homology groups of a closed orientable orbifold have a basis consisting of classes represented by “closed embedded full suborbifolds whose normal bundles have fiberwise trivial isotropy action”.\nIn other words, given a closed orientable orbifold \\(\\mathcal{O}\\) there exists a basis \\(\\{[\\mathcal{X}_i]\\}\\) of the rational homology groups \\(H_*(\\mathcal{O};\\mathbb{Q})\\) which consists of the fundamental classes of such “closed embedded full suborbifolds \\(\\mathcal{X}_i\\subset \\mathcal{O}\\) whose normal bundles have fiberwise trivial isotropy action”. Such a suborbifold is called a representing suborbifold.\nRepresenting suborbifolds are well-suited for general intersection theories. Given such a suborbifold, the underlying topological space of the normal bundle is a vector bundle over the underlying topological space of the suborbifold. In contrast, the underlying topological space of an arbitrary orbifold bundle will generally not be a vector bundle. This means it is possible to use single valued sections (as opposed to multisections) for arguments involving perturbations."
  },
  {
    "objectID": "mathematics-research.html#polyfold-gromovwitten-invariants-as-intersection-numbers",
    "href": "mathematics-research.html#polyfold-gromovwitten-invariants-as-intersection-numbers",
    "title": "Mathematics research",
    "section": "Polyfold Gromov–Witten invariants as intersection numbers",
    "text": "Polyfold Gromov–Witten invariants as intersection numbers\nThe earliest interpretations of the GW-invariants present in the literature were given in terms of counting a finite number of curves (McDuff and Salamon 2012; Ruan 1994, 1996). For example, Ruan described the GW-invariants as a finite sum, counted with multiplicity, of nonmultiple cover \\(J\\)-spheres in \\({\\mathcal M}^*_{(A,J)}\\) which intersect representatives of given cycles in the symplectic manifold (Ruan 1996, Thm. A).\nHowever, such definitions have previously been restricted to genus zero GW-invariants in semipositive symplectic manifolds. Observe that in the genus \\(0\\) case the Grothendieck–Knudsen spaces \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{0,k}\\) are finite-dimensional manifolds. In contrast, if genus \\(g &gt;0\\) the general Deligne–Mumford spaces \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) are orbifolds. Therefore, in the genus \\(0\\) case extant methods—such as representing a homology class as a pseudocycle in a manifold or, indeed, the Steenrod problem for manifolds—were sufficient to interpret the GW-invariants as an intersection number.\nUsing the Steenrod problem for orbifolds, I was able to prove that the polyfold GW-invariants may equivalently be defined as an intersection number. Let \\({\\mathcal S}_{A,g,k}(p)\\) be a perturbed GW-moduli space, and let \\({\\mathcal X}_1\\times \\cdots \\times {\\mathcal X}_k \\times {\\mathcal B}\\subset Q^k\\times \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) be a representing suborbifold. Consider the diagram:\n\\[\n\\begin{align*}\n{\\mathcal S}_{A,g,k}(p) \\xrightarrow{ev_1\\times \\cdots \\times ev_k \\times \\pi} M^k & \\times \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k} \\\\\n                                                                                                                                                    & \\cup \\\\\n                                                                                                                    {\\mathcal X}_1\\times \\cdots &\\times {\\mathcal X}_k \\times {\\mathcal B}.\n\\end{align*}\n\\]\nI showed that transversality of a perturbed solution space of a polyfold with a representing submanifolds/suborbifolds may always be achieved through either of the following:\n\nThrough the perturbation of the representing suborbifold; due to the properties of the normal bundle representing suborbifolds may always be perturbed (Schmaltz 2019a, Prop. 3.9).\nAssuming the map defined on the ambient polyfold is a submersion, we may obtain transversality through choice of a suitable abstract perturbation (Schmaltz 2019a, Prop. 3.10).\n\nWhen \\(\\dim {\\mathcal S}_{A,g,k}(p) + \\dim \\left({\\mathcal X}_1 \\times\\cdots\\times {\\mathcal X}_k \\times {\\mathcal B}\\right) = \\dim (M^k \\times \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k})\\) the intersection number is given by the signed weighted count of a finite number of points of intersection.\nTheorem (Schmaltz 2019a, Polyfold Gromov–Witten invariants as intersection numbers) The polyfold Gromov–Witten invariant may equivalently be defined as the intersection number evaluated on a basis of representing submanifolds \\({\\mathcal X}\\subset M\\) and representing suborbifolds \\({\\mathcal B}\\subset {\\mathcal O}\\):\n\\[\n    \\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) :=\n    \\left(ev_1\\times\\cdots\\times ev_k\\times\\pi\\right)|_{{\\mathcal S}_{A,g,k}(p)} \\cdot \\left({\\mathcal X}_1 \\times\\cdots\\times {\\mathcal X}_k \\times {\\mathcal B}\\right).\n\\]\nThe invariant does not depend on the choice of abstract perturbation, nor on the choice of representing basis.\nThus the traditional geometric interpretation of the GW-invariants as a “count of curves” is made literal.\n\n\n\nA Gromov–Witten invariant"
  },
  {
    "objectID": "mathematics-research.html#a-polyfold-proof-of-the-gromovwitten-axioms",
    "href": "mathematics-research.html#a-polyfold-proof-of-the-gromovwitten-axioms",
    "title": "Mathematics research",
    "section": "A polyfold proof of the Gromov–Witten axioms",
    "text": "A polyfold proof of the Gromov–Witten axioms\nWith a fully general polyfold Gromov–Witten invariant in place, a natural question is:\n\nTo what extent does this newly defined invariant satisfy traditional results of GW-theory for symplectic manifolds?\n\nA natural place to begin is with verifying the GW-axioms, as first stated by Kontsevich and Manin (1994).\nTheorem (Schmaltz 2019c, Polyfold Gromov–Witten axioms) The polyfold Gromov–Witten invariants satisfy the Gromov–Witten axioms.\nTheorem. The polyfold Gromov–Witten invariants satisfy the following Gromov–Witten axioms:\nEffective axiom. If \\(\\omega(A)&lt;0\\) then \\(\\mathop{\\mathrm{GW}}_{A,g,k} = 0\\).\nGrading axiom. If \\(\\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\beta) \\neq 0\\) then\n\\[\n    \\sum_{i=1}^k (2n - \\deg (\\alpha_i)) + (6g-6+2k - \\deg(\\beta)) = 2c_1(A) + (2n - 6)(1-g) + 2k.\n\\]\nHomology axiom. There exists a homology class\n\\[\n        \\sigma_{A,g,k} \\in H_{2c_1(A) + (2n-6)(1-g) + 2k} (M^k\\times \\bar{\\mathcal{M}}_{g,k};{\\mathbb Q})\n\\]\nsuch that\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\beta) = \\langle p_1^* \\mathop{\\mathrm{PD}}(\\alpha_1) \\smallsmile \\cdots \\smallsmile p_k^*\\mathop{\\mathrm{PD}}(\\alpha_k) \\smallsmile p_0^*\\mathop{\\mathrm{PD}}(\\beta), \\sigma_{A,g,k} \\rangle\n\\]\nwhere \\(p_i: M^k \\times \\bar{\\mathcal{M}}_{g,k} \\to M\\) denotes the projection onto the \\(i\\)th factor and the map \\(p_0:M^k \\times \\bar{\\mathcal{M}}_{g,k}\\to\\bar{\\mathcal{M}}_{g,k}\\) denotes the projection onto the last factor.\nZero axiom. If \\(A=0,\\ g=0\\) then \\(\\mathop{\\mathrm{GW}}_{0,0,k} (\\alpha_1,\\ldots,\\alpha_k;\\beta) = 0\\) whenever \\(\\deg (\\beta) &gt;0\\), and\n\\[\n        \\mathop{\\mathrm{GW}}_{0,0,k} (\\alpha_1,\\ldots,\\alpha_k; [\\operatorname{pt}]) = \\int_M \\mathop{\\mathrm{PD}}(\\alpha_1) \\wedge \\cdots \\wedge \\mathop{\\mathrm{PD}}(\\alpha_k).\n\\]\nSymmetry axiom. Fix a permutation \\(\\sigma: \\{1,\\ldots, k\\}\\to \\{1,\\ldots,k\\}\\). Consider the permutation map \\(\\sigma:\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}, \\ [\\Sigma,j,M,D]  \\mapsto [\\Sigma,j,M^\\sigma,D]\\) where \\(M = \\{z_1,\\ldots,z_k\\}\\) and where \\(M^\\sigma := \\{z'_1,\\ldots,z'_k\\},\\) \\(z'_i:= z_{\\sigma(i)}\\). Then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_{\\sigma(1)},\\ldots,\\alpha_{\\sigma(k)}; \\sigma_*\\beta) = (-1)^{N(\\sigma;\\alpha_i)} \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\beta)\n\\]\nwhere \\(N(\\sigma;\\alpha_i):= \\sharp    \\{  i&lt;j \\mid \\sigma(i)&gt; \\sigma(j), \\deg (\\alpha_i)\\deg(\\alpha_j)\\in 2{\\mathbb Z}+1\\}\\).\nDefinition. (Kontsevich and Manin 1994, Eq. 2.3) We say that \\((A,g,k)\\) is a basic class if it is equal to one of the following: \\((A,0,3)\\), \\((A,1,1)\\), or \\((A,g\\geq 2,0)\\).\nThe point is, for such values of \\(g\\) and \\(k\\) we will have \\(\\bar{\\mathcal{M}}_{g,k-1} = \\emptyset\\) by definition.\nFundamental class axiom. Consider the fundamental classes \\([M]\\in H_{2n}(M;{\\mathbb Q})\\) and \\([\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}] \\in H_{6g-6+2k}(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k};{\\mathbb Q})\\). Suppose that \\(A\\neq 0\\) and that \\((A,g,k)\\) is not basic. Then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_{k-1},[M]; [\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}]) = 0.\n\\]\nConsider the canonical section \\(s_i :\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k-1} \\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) defined by doubling the \\(i\\)th-marked point. Then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_{k-1},[M]; s_{i*}\\beta) = \\mathop{\\mathrm{GW}}_{A,g,k-1} (\\alpha_1,\\ldots,\\alpha_{k-1};\\beta).\n\\]\nDivisor axiom. Suppose \\((A,g,k)\\) is not basic. If \\(\\deg (\\alpha_k) = 2n-2\\) then\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k; \\mathop{\\mathrm{PD}}(ft_k^* \\mathop{\\mathrm{PD}}(\\beta))) = (A\\cdot \\alpha_k ) \\ \\mathop{\\mathrm{GW}}_{A,g,k-1} (\\alpha_1,\\ldots,\\alpha_{k-1};\\beta),\n\\]\nwhere \\(A\\cdot \\alpha_k\\) is given by the homological intersection product.\nLet \\(\\{e_\\nu \\} \\in H^*(M;{\\mathbb Q})\\) be a homogeneous basis and let \\(\\{e^\\mu \\} \\in H^*(M;{\\mathbb Q})\\) be the dual basis with respect to Poincaré duality, i.e., \\(\\langle e_\\nu \\smallsmile e^\\mu, [M] \\rangle = \\delta_{\\nu \\mu}\\). It follows from the Künneth formula that \\(\\{e_\\nu \\otimes e^\\mu \\}\\) is a basis for \\(H^*(M\\times M;{\\mathbb Q})\\). We correct the sign by redefining \\(e_\\nu\\) as \\((-1)^{\\deg e_\\nu} e_\\nu\\). We can write the Poincaré dual of the diagonal \\(\\Delta \\subset M\\times M\\) in this basis as \\(\\mathop{\\mathrm{PD}}([\\Delta]) = \\sum_\\nu e_\\nu \\otimes e^\\nu\\).\nSplitting axiom. Fix a partition \\(S_0 \\sqcup S_1 =\\{1,\\ldots, k\\}\\). Let \\(k_0 := \\sharp S_0\\), \\(k_1 := \\sharp S_1\\) and let \\(g_0\\), \\(g_1 \\geq 0\\) such that \\(g = g_0 + g_1\\), and \\(k_i + g_i \\geq 2\\) for \\(i=0,1\\). Consider the natural map \\[\\phi_S : \\bar{\\mathcal{M}}_{k_0+1 , g_0}\\times \\bar{\\mathcal{M}}_{k_1+1 , g_1} \\to \\bar{\\mathcal{M}}_{g,k}\\] which identifies the last marked point of a stable noded Riemann surface in \\(\\bar{\\mathcal{M}}_{k_0+1 , g_0}\\) with the first marked point of a stable noded Riemann surface in \\(\\bar{\\mathcal{M}}_{k_1+1, g_1}\\), and which maps the first \\(k_0\\) marked points of \\(\\bar{\\mathcal{M}}_{g_0,k_0+1}\\) to marked points indexed by \\(S_0\\) and likewise maps the last \\(k_1\\) marked points of \\(\\bar{\\mathcal{M}}_{g_1,k_1+1}\\) to marked points indexed by \\(S_1\\). Then\n\\[\n    \\begin{align*}\n         & \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1, \\ldots, \\alpha_k; \\phi_{S*} (\\beta_0\\otimes \\beta_1) ) =\n        (-1)^{N(S;\\alpha)} \\sum_{A_0+A_1 = A}   \\sum_\\nu                                     \\\\\n         & \\qquad\n        \\mathop{\\mathrm{GW}}_{A_0,g_0,k_0+1} (\\{\\alpha_i\\}_{i\\in S_0}, \\mathop{\\mathrm{PD}}(e_\\nu) ; \\beta_0)\n        \\cdot\n        \\mathop{\\mathrm{GW}}_{A_1,g_1,k_1+1} (\\mathop{\\mathrm{PD}}(e^\\nu), \\{\\alpha_j\\}_{j\\in S_1} ; \\beta_1)\n    \\end{align*}\n\\]\nwhere \\(N(S;\\alpha)=\\sharp \\{j&lt;i \\mid i\\in S_0, j\\in S_1, \\deg(\\alpha_i)\\deg(\\alpha_j)\\in 2{\\mathbb Z}+1 \\}\\).\nGenus reduction axiom. Consider the natural map \\[\\psi: \\bar{\\mathcal{M}}_{g-1,k+2} \\to \\bar{\\mathcal{M}}_{g,k}\\] which identifies the last two marked points of a stable noded Riemann surface, increasing the arithmetic genus by one. Then\n\\[\n  2 \\cdot \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1, \\ldots, \\alpha_k; \\psi_* \\beta) = \\sum_\\nu \\mathop{\\mathrm{GW}}_{A,g-1,k+2} (\\alpha_1,\\ldots,\\alpha_k, \\mathop{\\mathrm{PD}}(e_\\nu) , \\mathop{\\mathrm{PD}}(e^\\nu) ; \\beta).\n\\]"
  },
  {
    "objectID": "mathematics-research.html#strategy-of-the-proof-of-the-gromovwitten-axioms",
    "href": "mathematics-research.html#strategy-of-the-proof-of-the-gromovwitten-axioms",
    "title": "Mathematics research",
    "section": "Strategy of the proof of the Gromov–Witten axioms",
    "text": "Strategy of the proof of the Gromov–Witten axioms\nThe Gromov–Witten axioms give relationships between the Gromov–Witten invariants. These relationships are determined by the geometry of certain naturally defined maps defined between the unperturbed Gromov–Witten moduli spaces, namely:\n\npermutation maps, \\[\\sigma : \\bar{\\mathcal{M}}_{A,g,k}(J) \\to \\bar{\\mathcal{M}}_{A,g,k}(J),\\]\n\\(k\\)th-marked point forgetting maps, \\[ft_k : \\bar{\\mathcal{M}}_{A,g,k}(J) \\to \\bar{\\mathcal{M}}_{A,g,k-1}(J),\\]\ncanonical sections, \\[s_i : \\bar{\\mathcal{M}}_{A,g,k-1}(J) \\hookrightarrow \\bar{\\mathcal{M}}_{A,g,k}(J).\\]\n\nFurthermore, using the map\n\\[\n    ev_{k_0+1} \\times ev_1 : \\bar{\\mathcal{M}}_{A_0,g_0,k_0+1}(J) \\times \\bar{\\mathcal{M}}_{A_1,g_1,k_1+1}(J) \\to M\\times M\n\\]\nwe may consider the subset \\((ev_{k_0+1} \\times ev_1 )^{-1}(\\Delta)\\) of the product unperturbed Gromov–Witten moduli space with a constraint imposed by the diagonal \\(\\Delta \\subset M\\times M\\). We then additionally have:\n\ninclusion maps, and maps \\(\\phi\\) which identify the marked points \\(z_{k_0+1}\\) and \\(z_1'\\), \\[\n  \\begin{align*}\n      \\bar{\\mathcal{M}}_{A_0,g_0,k_0+1}(J) & \\times \\bar{\\mathcal{M}}_{A_1,g_1,k_1+1}(J) \\\\\n      i \\bigg{\\uparrow} & \\\\\n      (ev_{k_0+1} & \\times ev_1 )^{-1}(\\Delta) \\xrightarrow{\\phi} \\bar{\\mathcal{M}}_{A_0+A_1,g_0+g_1,k_0+k_1}(J)\n  \\end{align*}\n\\] Likewise, using the map \\(ev_{k+1} \\times ev_{k+2} : \\bar{\\mathcal{M}}_{A,g-1,k+2}(J) \\to M\\times M\\) we may consider the subset \\((ev_{k+1} \\times ev_{k+2} )^{-1}(\\Delta)\\) of the unperturbed Gromov–Witten moduli space with a constraint imposed by the diagonal \\(\\Delta \\subset M\\times M\\). We then additionally have:\ninclusion maps, and maps \\(\\psi\\) which identify the marked points \\(z_{k+1}\\) and \\(z_{k+2}\\) (increasing the arithmetic genus by one), \\[\n  \\begin{align*}\n      \\bar{\\mathcal{M}}_{A,g-1,k+2}& (J)    \\\\\n      i \\bigg{\\uparrow} \\qquad &\\\\\n      (ev_{k+1} \\times ev_{k+2}& )^{-1}(\\Delta) \\xrightarrow{\\psi} \\bar{\\mathcal{M}}_{A,g,k}(J)\n  \\end{align*}\n\\]\n\nIntuitively, we should prove the Gromov–Witten axioms by interpreting the Gromov–Witten invariants as a finite count of curves and using the geometry of the above maps to directly compare such counts with respect to constraints imposed by the homology classes on \\(M\\) and \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\).\nA substantial amount of work is required to make this intuition rigorous in the context of an abstract perturbation theory. A deep understanding of the full machinery of polyfold theory, in addition to the geometry of the Gromov–Witten invariants is necessary to navigate substantial difficulties that we encounter."
  },
  {
    "objectID": "mathematics-research.html#difficulties-in-proving-the-polyfold-gromovwitten-axioms",
    "href": "mathematics-research.html#difficulties-in-proving-the-polyfold-gromovwitten-axioms",
    "title": "Mathematics research",
    "section": "Difficulties in proving the polyfold Gromov–Witten axioms",
    "text": "Difficulties in proving the polyfold Gromov–Witten axioms\nProving this required a substantial amount of work, and relied on the results of (Schmaltz 2019b, 2019a). The GW-axioms give relationships between the GW-invariants. These relationships are determined by the geometry of certain naturally defined maps defined between the unperturbed GW-moduli spaces, namely the permutation maps, the \\(k\\)th-marked point forgetting maps, in addition to certain natural maps which identify marked points into nodal pairs, where the GW-moduli space is subject to a diagonal constraint. With the exception of the \\(k\\)th-marked point forgetting maps, we may pullback abstract perturbations in order to obtain well-defined restricted maps between perturbed GW-moduli spaces.\nThe branched integral is useful for giving a well-defined definition of the polyfold GW-invariants and moreover showing that they are, in fact, invariants and do not depend on choices. But integration is not the best viewpoint for giving a proof of all of the axioms. Intuitively, we should prove the GW-axioms by interpreting the GW-invariants as an intersection number and using the geometry of the above maps to directly compare such counts with respect to constraints imposed by the homology classes on \\(M\\) and \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\). And indeed, via (Schmaltz 2019a) this intuition is made rigorous, and is precisely my approach to proving the axioms.\nHowever, problems arise when we try to define a \\(k\\)th-marked point forgetting map between perturbed GW-moduli spaces—such a map does not even exist. The construction of the smooth structure for the DM-orbifolds as described in (Hofer, Wysocki, and Zehnder 2017) and (Hofer, Wysocki, and Zehnder, n.d.) requires a choice: that of a “gluing profile,” i.e., a smooth diffeomorphism \\(\\varphi: (0,1]\\to [0,\\infty).\\) Given a noded Riemann surface and a nonzero parameter \\(a \\in {\\mathbb C}\\) we use the gluing profile to replace a region of the node with a cylinder of finite length \\(\\varphi(\\lvert a\\rvert)\\). The logarithmic gluing profile is given by \\(\\varphi_{\\log} (r) = -\\frac{1}{2\\pi} \\log (r)\\) and produces the classical holomorphic DM-orbifolds \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\). There is also an exponential gluing profile, given by \\(\\varphi_{\\exp} (r) = e^{1/r} - e\\) which produces DM-orbifolds \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{exp}}_{g,k}\\) which are only smooth orbifolds. The exponential gluing profile is required for the scale smoothness of certain maps used to define the GW-polyfolds.\nThis use of nonstandard smooth structure has the following consequence:\n\nProblem 1. In general the map \\(ft_k: \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{exp}}_{g,k} \\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{exp}}_{g,k-1}\\) is continuous but not differentiable.\n\nIndependent of the usage of a nonstandard gluing profile, there is no hope whatsoever of defining a \\(k\\)th-marked point forgetting map on the GW-polyfolds as they are defined:\n\nProblem 2. In general there does not exist a natural map \\(ft_k\\) on the Gromov–Witten polyfolds.\n\nTo explain, a stable curve in \\({\\mathcal Z}_{A,g,k}\\) may contain a “destabilizing ghost component,” i.e., a component \\(C_k\\simeq S^2\\) with precisely \\(3\\) special points, one of which is the \\(k\\)th-marked point, and such that \\(\\int_{C_k} u^*\\omega=0,\\) \\(u|_{C_k} \\neq\\text{const}.\\) After removal of the \\(k\\)th-marked point from such a component we cannot consider the resulting data as a stable curve in \\({\\mathcal Z}_{A,g,k-1}\\).\nWe might try to restrict to a subset \\({\\mathcal Z}^\\text{const}_{A,g,k}\\subset {\\mathcal Z}_{A,g,k}\\) consisting of stable curves which are constant on such destabilizing ghost components. The \\(k\\)th-marked point forgetting map is then well-defined on this subset. However, if we consider \\(\\mathcal{Z}^\\text{const}_{A,g,k}\\subset \\mathcal{Z}_{A,g,k}\\) with the subspace topology, and \\(\\mathcal{Z}_{A,g,k-1}\\) with the usual polyfold topology, then:\n\nProblem 3. In general the well-defined restriction \\(ft_k:{\\mathcal Z}_{A,g,k}^\\text{const} \\to \\mathcal{Z}_{A,g,k-1}\\) is not continuous.\n\nIn essence the central problem is that the GW-polyfolds as constructed are not “universal curves”. Our proof of the GW-axioms rectifies this by constructing a universal curve polyfold \\({\\mathcal Z}^\\text{uc}_{A,g,k}\\) over \\({\\mathcal Z}_{A,g,k-1}\\), on which we may consider a well-defined \\(k\\)th-marked point forgetting map\n\\[\n    ft_k : {\\mathcal Z}^\\text{uc}_{A,g,k} \\to {\\mathcal Z}_{A,g,k-1}.\n\\]\nThe preimage of stable curve in \\({\\mathcal Z}_{A,g,k-1}\\) via \\(ft_k\\) can be identified with the underlying Riemann surface with nodes identified, thereby explaining the choice of nomenclature “universal curve”. It is possible to pullback regular perturbations via this map, and hence obtain a well-defined map between perturbed GW-moduli spaces.\nThere is a final problem. In general, the projection map must factor through the \\(k\\)th-marked point forgetting map; this is due to the need to forget the added stabilizing points. Thus, in order to obtain a smooth projection map we must map to the logarithmic DM-orbifold. However:\n\nProblem 4. While the projection \\(\\pi : {\\mathcal Z}_{A,g,k} \\to \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) is \\(\\text{sc}\\)-smooth, in general it is not a submersion.\n\nThis has important consequences if we wish to consider the GW-invariant as an intersection number; the only way to get transversality of the projection map with a representing suborbifold \\({\\mathcal B}\\subset \\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\) is through perturbation of the suborbifold. This is made possible by the existence of representing suborbifolds, for which perturbation is possible, the existence of which is guaranteed by (Schmaltz 2019a)."
  },
  {
    "objectID": "mathematics-research.html#pseudocycle-gromovwitten-invariants-are-a-strict-subset-of-polyfold-gromovwitten-invariants",
    "href": "mathematics-research.html#pseudocycle-gromovwitten-invariants-are-a-strict-subset-of-polyfold-gromovwitten-invariants",
    "title": "Mathematics research",
    "section": "Pseudocycle Gromov–Witten invariants are a strict subset of polyfold Gromov–Witten invariants",
    "text": "Pseudocycle Gromov–Witten invariants are a strict subset of polyfold Gromov–Witten invariants\nThere were of course, earlier attempts at rigourously definining the Gromov–Witten invariants prior to the fully general definition of the polyfold Gromov–Witten invariant. The most common of these is the classical pseudocycle Gromov–Witten invariant, defined only for genus-zero and for semipositive symplectic manifolds.\nThe “semipositive” condition was first introduced by McDuff in 1991 in (McDuff 1991), and is specifically designed to guarantee that in the genus-zero case, the strata of nodal \\(J\\)-curves will have codimension at least \\(2\\) relative to the dimension of the top stratum of non-noded simple \\(J\\)-curves. For semipositive symplectic manifolds, the space of genus-zero \\(J\\)-curves has the structure of a pseudocycle. Around the end of 1993, GW-invariants for genus-zero were first rigorously defined for semipositive symplectic manifolds by Ruan–Tian in (Ruan and Tian 1995).\nA symplectic manifold \\((M^{2n},\\omega)\\) is called semipositive if, for every \\(A\\in \\pi_2(M)\\),\n\\[\n    \\omega(A) &gt;0,\\ c_1(A) \\geq 3-n \\quad \\implies \\quad c_1(A) \\geq 0.\n\\]\nI unified the classical definition of a Gromov–Witten invariant as a pseudocycle and the modern definition of a Gromov–Witten invariant via polyfold theory by proving they are equivalent.\nTheorem. (Schmaltz 2023, Main result) For a given semipositive symplectic manifold, the pseudocycle genus-zero Gromov–Witten invariants are equal to the polyfold genus-zero Gromov–Witten invariants.\nSince the polyfold GW-invariants are also defined for general symplectic manifolds and for arbitrary genus, we have\n\\[\n    \\left\\{ \\begin{array}{c} \\textit{pseudocycle} \\\\ \\textit{Gromov-Witten} \\\\ \\textit{invariants} \\end{array} \\right\\}\n    \\subsetneq\n    \\left\\{ \\begin{array}{c} \\textit{polyfold} \\\\ \\textit{Gromov-Witten} \\\\ \\textit{invariants} \\end{array} \\right\\}.\n\\]\n\nReferences\n\n\nEilenberg, Samuel. 1949. “On the Problems of Topology.” Ann. Of Math. (2) 50: 247–60. https://doi.org/10.2307/1969448.\n\n\nHofer, Helmut, Kris Wysocki, and Eduard Zehnder. 2017. “Applications of Polyfold Theory I: The Polyfolds of Gromov– Witten Theory.” Mem. Amer. Math. Soc. 248 (1179): v+218. https://doi.org/10.1090/memo/1179.\n\n\n———. n.d. “Deligne–Mumford-Type Spaces with a View Towards Symplectic Field Theory.”\n\n\nKontsevich, Maxim, and Yuri Manin. 1994. “Gromov–Witten Classes, Quantum Cohomology, and Enumerative Geometry.” Comm. Math. Phys. 164 (3): 525–62. http://projecteuclid.org/euclid.cmp/1104270948.\n\n\nMcDuff, Dusa. 1991. “Symplectic Manifolds with Contact Type Boundaries.” Invent. Math. 103 (3): 651–71. https://doi.org/10.1007/BF01239530.\n\n\nMcDuff, Dusa, and Dietmar Salamon. 2012. \\(J\\)-Holomorphic Curves and Symplectic Topology. Second. Vol. 52. American Mathematical Society Colloquium Publications. American Mathematical Society, Providence, RI.\n\n\nRuan, Yongbin. 1994. “Symplectic Topology on Algebraic \\(3\\)-Folds.” J. Differential Geom. 39 (1): 215–27. http://projecteuclid.org/euclid.jdg/1214454682.\n\n\n———. 1996. “Topological Sigma Model and Donaldson-Type Invariants in Gromov Theory.” Duke Math. J. 83 (2): 461–500. https://doi.org/10.1215/S0012-7094-96-08316-7.\n\n\nRuan, Yongbin, and Gang Tian. 1995. “A Mathematical Theory of Quantum Cohomology.” J. Differential Geom. 42 (2): 259–367. http://projecteuclid.org/euclid.jdg/1214457234.\n\n\nSchmaltz, Wolfgang. 2019a. “The Steenrod problem for orbifolds and polyfold invariants as intersection numbers.” arXiv e-Prints. April 2019. https://arxiv.org/abs/1904.02186.\n\n\n———. 2019b. “Naturality of polyfold invariants and pulling back abstract perturbations.” arXiv e-Prints. December 2019. https://arxiv.org/abs/1912.13370.\n\n\n———. 2019c. “The Gromov–Witten axioms for symplectic manifolds via polyfold theory.” arXiv e-Prints. December 2019. https://arxiv.org/abs/1912.13374.\n\n\n———. 2023. “Pseudocycle Gromov-Witten invariants are a strict subset of polyfold Gromov-Witten invariants.” arXiv e-Prints. https://doi.org/10.48550/arXiv.2308.14204.\n\n\nThom, René. 1954. “Quelques Propriétés Globales Des Variétés Diffé Rentiables.” Comment. Math. Helv. 28: 17–86. https://doi.org/10.1007/BF02566923."
  },
  {
    "objectID": "fastai-1.html",
    "href": "fastai-1.html",
    "title": "Wolfgang Schmaltz",
    "section": "",
    "text": "::: {#cell-0 .cell _kg_hide-input=‘false’ _kg_hide-output=‘false’ execution=‘{“iopub.execute_input”:“2023-03-09T12:56:53.917785Z”,“iopub.status.busy”:“2023-03-09T12:56:53.916489Z”,“iopub.status.idle”:“2023-03-09T12:57:07.982541Z”,“shell.execute_reply”:“2023-03-09T12:57:07.981391Z”,“shell.execute_reply.started”:“2023-03-09T12:56:53.917689Z”}’ execution_count=1}\n:::\nIn this short notebook, I build a classifier to determine whether an image is a beetle or The Beatles!",
    "crumbs": [
      "Deep Learning",
      "1 - Building a simple model"
    ]
  },
  {
    "objectID": "fastai-1.html#step-1-download-images-of-beetles-and-the-beatles",
    "href": "fastai-1.html#step-1-download-images-of-beetles-and-the-beatles",
    "title": "Wolfgang Schmaltz",
    "section": "Step 1: Download images of beetles and The Beatles",
    "text": "Step 1: Download images of beetles and The Beatles\nUsing the python package ddg_search we begin by searching for images of beetles and The Beatles.\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\n\ndownload_url(search_images('beetles', max_images=1)[0], 'beetle.jpg', show_progress=False)\n#Image.open('beetle.jpg').to_thumb(256,256)\n\nSearching for 'beetles'\n\n\nPath('beetle.jpg')\n\n\n\ndownload_url(search_images('the Beatles', max_images=1)[0], 'the_beatles.jpg', show_progress=False)\n#Image.open('the_beatles.jpg').to_thumb(256,256)\n\nSearching for 'the Beatles'\n\n\nPath('the_beatles.jpg')\n\n\nWe now save searches for beetles and The Beetles into folders.\n\nsearches = 'beetles','the Beatles'\npath = Path('beetle_or_the_Beatles')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o}'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'beetles'\nSearching for 'the Beatles'",
    "crumbs": [
      "Deep Learning",
      "1 - Building a simple model"
    ]
  },
  {
    "objectID": "fastai-1.html#step-2-train-a-model",
    "href": "fastai-1.html#step-2-train-a-model",
    "title": "Wolfgang Schmaltz",
    "section": "Step 2: Train a model",
    "text": "Step 2: Train a model\nWe remove photos which didn’t download correctly.\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n2\n\n\nWe use a ‘Datablock’ to separate the data into training and validation sets.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\nWe now use ‘resnet18’ to train our model, and the ‘fine_tune()’ method from ‘fastai’ to tune the model.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.623580\n4.855602\n0.545455\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.892229\n3.018108\n0.545455\n00:04\n\n\n1\n0.693663\n0.710887\n0.272727\n00:04\n\n\n2\n0.487951\n0.266973\n0.090909\n00:04",
    "crumbs": [
      "Deep Learning",
      "1 - Building a simple model"
    ]
  },
  {
    "objectID": "fastai-1.html#step-3-test-the-model",
    "href": "fastai-1.html#step-3-test-the-model",
    "title": "Wolfgang Schmaltz",
    "section": "Step 3: Test the model",
    "text": "Step 3: Test the model\nWe can now test our model on the images of a beetle and of the Beatles we downloaded in Step 1.\n\nImage.open('beetle.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\n\nis_beetle,_,probs = learn.predict('beetle.jpg')\nprint(f\"This is a: {is_beetle}.\")\nprint(f\"Probability it's a beetle: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: beetles.\nProbability it's a beetle: 1.0000\n\n\n\nImage.open('the_beatles.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\n\nis_the_beatles,_,probs = learn.predict('the_beatles.jpg')\nprint(f\"This is a: {is_the_beatles}.\")\nprint(f\"Probability it's the Beatles: {probs[1]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: the Beatles.\nProbability it's the Beatles: 0.9777",
    "crumbs": [
      "Deep Learning",
      "1 - Building a simple model"
    ]
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Wolfgang Schmaltz",
    "section": "Education",
    "text": "Education\nPhD in Mathematics\nUniversity of California, Berkeley | Berkeley, CA\n16 August 2012 - 11 May 2018\nB.S. in Mathematics\nUniversity of Chicago | Chicago, IL\n24 September 2007 - 11 June 2011"
  },
  {
    "objectID": "index.html#postdoctoral-appointments",
    "href": "index.html#postdoctoral-appointments",
    "title": "Wolfgang Schmaltz",
    "section": "Postdoctoral Appointments",
    "text": "Postdoctoral Appointments\nFaculty of Mathematics\nRuhr-Universität Bochum | Bochum, Germany\n1 March 2020 - Present\nMathematics Institute\nJustus-Liebig University | Gießen, Germany\n1 January 2018 - 29 February 2020"
  },
  {
    "objectID": "deep_learning.html",
    "href": "deep_learning.html",
    "title": "DEEP LEARNING!",
    "section": "",
    "text": "Less is more.\nImplement and demonstrate a ‘which beetle are you’ classifier\nDecision Tree with Visualization\n\n\n\n\nBuild a model on some data\n\n\n\n\n\nFramework from Rob Mulla\nFacebook Prophet\nBest results from kaggle course\nPredict energy market time series data via timeseriesAI\n\nComment on Max Dama’s quote on machine learning\n\n\n\n\n\n\nBuild a miniGPT?\n\n\n\n\n\nPlay with Stable Diffusion",
    "crumbs": [
      "Deep Learning"
    ]
  },
  {
    "objectID": "deep_learning.html#hand-made-neural-network",
    "href": "deep_learning.html#hand-made-neural-network",
    "title": "DEEP LEARNING!",
    "section": "",
    "text": "Build a model on some data",
    "crumbs": [
      "Deep Learning"
    ]
  },
  {
    "objectID": "deep_learning.html#time-series-analysis",
    "href": "deep_learning.html#time-series-analysis",
    "title": "DEEP LEARNING!",
    "section": "",
    "text": "Framework from Rob Mulla\nFacebook Prophet\nBest results from kaggle course\nPredict energy market time series data via timeseriesAI\n\nComment on Max Dama’s quote on machine learning",
    "crumbs": [
      "Deep Learning"
    ]
  },
  {
    "objectID": "deep_learning.html#natural-language-processing",
    "href": "deep_learning.html#natural-language-processing",
    "title": "DEEP LEARNING!",
    "section": "",
    "text": "Build a miniGPT?",
    "crumbs": [
      "Deep Learning"
    ]
  },
  {
    "objectID": "deep_learning.html#stable-diffusion",
    "href": "deep_learning.html#stable-diffusion",
    "title": "DEEP LEARNING!",
    "section": "",
    "text": "Play with Stable Diffusion",
    "crumbs": [
      "Deep Learning"
    ]
  },
  {
    "objectID": "climbing.html#the-5-classic-7as",
    "href": "climbing.html#the-5-classic-7as",
    "title": "Climbing",
    "section": "The 5 Classic 7As",
    "text": "The 5 Classic 7As"
  },
  {
    "objectID": "climbing.html#the-long-legs-of-gullich",
    "href": "climbing.html#the-long-legs-of-gullich",
    "title": "Climbing",
    "section": "The Long Legs of Gullich",
    "text": "The Long Legs of Gullich"
  },
  {
    "objectID": "climbing.html#italy---ragno-di-mare",
    "href": "climbing.html#italy---ragno-di-mare",
    "title": "Climbing",
    "section": "Italy - Ragno di Mare",
    "text": "Italy - Ragno di Mare"
  },
  {
    "objectID": "climbing.html#the-wilder-kaiser",
    "href": "climbing.html#the-wilder-kaiser",
    "title": "Climbing",
    "section": "The Wilder Kaiser",
    "text": "The Wilder Kaiser"
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "hello.html#polar-axis",
    "href": "hello.html#polar-axis",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "fastai-3.html",
    "href": "fastai-3.html",
    "title": "Comparing computer vision models",
    "section": "",
    "text": "As newcomers in the world of deep learning, we are told that we can generally treat pre-trained computer vision models as ‘black boxes’, without understanding the inner workings of the models. On this page, we will compare the performance of some of the state-of-the-art computer vision models. In doing so, we gain a better mental map of what performance looks like on the cutting edge, as well as demonstrating some of the visualization tools of data analysis.\nWe use the state-of-the-art computer vision models from PyTorch Image Models (timm). Our benchmarks for these models were collected by Ross Wightman and come from his GitHub. Our analysis is based on Jeremey Howard’s orignal analysis.",
    "crumbs": [
      "Deep Learning",
      "3 - Comparing computer vision models"
    ]
  },
  {
    "objectID": "fastai-3.html#commentary-on-findings",
    "href": "fastai-3.html#commentary-on-findings",
    "title": "Comparing computer vision models",
    "section": "Commentary on findings",
    "text": "Commentary on findings\nThe LeViT family models are both fast and accurate. Apparently these models are constructed using a hybrid of convolution neural networks and transformets.\nThe Swin family of transformers is apparently among the most accurate. It is described as a “hierarchical Transformer whose representation is computed with shifted windows.”",
    "crumbs": [
      "Deep Learning",
      "3 - Comparing computer vision models"
    ]
  },
  {
    "objectID": "fastai-3.html#speed-vs-parameter-count",
    "href": "fastai-3.html#speed-vs-parameter-count",
    "title": "Comparing computer vision models",
    "section": "Speed vs parameter count",
    "text": "Speed vs parameter count\nWe finally compare speed vs parameter count. Often, parameter count is used in papers as a proxy for speed. However, as we see, there is a wide variation in speeds at each level of parameter count, so it’s really not a useful proxy. There is sometimes a correlation between parameter count and needed memory, but this is also not always so useful. In the following chart: - the x axis shows the parameter count in a log scale - the y axis shows the speed in seconds in a log scale.\n\npx.scatter(df, width=w, height=h,\n    x='param_count_x',  y='secs', log_x=True, log_y=True, color='infer_img_size',\n    hover_name='model', hover_data=['infer_samples_per_sec', 'family']\n)",
    "crumbs": [
      "Deep Learning",
      "3 - Comparing computer vision models"
    ]
  },
  {
    "objectID": "fastai-2.html",
    "href": "fastai-2.html",
    "title": "Step 1: Download images of the Beatles using DuckDuckGo",
    "section": "",
    "text": "::: {#589f3b17 .cell _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ execution=‘{“iopub.execute_input”:“2023-03-09T22:02:42.432683Z”,“iopub.status.busy”:“2023-03-09T22:02:42.432353Z”,“iopub.status.idle”:“2023-03-09T22:02:57.541452Z”,“shell.execute_reply”:“2023-03-09T22:02:57.540385Z”}’ papermill=‘{“duration”:15.121345,“end_time”:“2023-03-09T22:02:57.544044”,“exception”:false,“start_time”:“2023-03-09T22:02:42.422699”,“status”:“completed”}’ tags=‘[]’ execution_count=1}\n:::\nfrom duckduckgo_search import ddg_images\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\nWe save images in ‘searches’ to train the model. We remove images which didn’t download correctly.\nsearches = 'John Lennon', 'Paul McCartney', 'Ringo Starr', 'George Harrison'\npath = Path('the_Beatles')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o}', 150))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    #resize_images(path/o, max_size=400, dest=path/o)\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\nSearching for 'John Lennon'\nSearching for 'Paul McCartney'\nSearching for 'Ringo Starr'\nSearching for 'George Harrison'\n\n\n19",
    "crumbs": [
      "Deep Learning",
      "2 - Which member of 'The Beatles' are you?"
    ]
  },
  {
    "objectID": "fastai-2.html#step-2-augment-the-data",
    "href": "fastai-2.html#step-2-augment-the-data",
    "title": "Step 1: Download images of the Beatles using DuckDuckGo",
    "section": "Step 2: Augment the data",
    "text": "Step 2: Augment the data\nWe use a ‘Datablock’ to separate the data into training and validation sets.\n\ndata = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\ndls = data.dataloaders(path)\ndls.valid.show_batch(max_n=6, nrows=2)\n\n\n\n\n\n\n\n\nPad the images with black:\n\ndata=data.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeros'))\ndls = data.dataloaders(path)\ndls.valid.show_batch(max_n=6, nrows=2)\n\n\n\n\n\n\n\n\nSquish the images:\n\ndata.new(item_tfms=Resize(128, ResizeMethod.Squish))\ndls = data.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2)\n\n\n\n\n\n\n\n\nTransform with Random Resized Crop:\n\ndata.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\ndls = data.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2, unique=True)\n\n\n\n\n\n\n\n\nExample of data augmentation using aug_transforms:\n\ndata = data.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\ndls = data.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2, unique=True)",
    "crumbs": [
      "Deep Learning",
      "2 - Which member of 'The Beatles' are you?"
    ]
  },
  {
    "objectID": "fastai-2.html#step-3-train-the-model-and-clean-some-of-the-data-by-hand",
    "href": "fastai-2.html#step-3-train-the-model-and-clean-some-of-the-data-by-hand",
    "title": "Step 1: Download images of the Beatles using DuckDuckGo",
    "section": "Step 3: Train the model and clean some of the data by hand",
    "text": "Step 3: Train the model and clean some of the data by hand\n\ndata = data.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\ndls = data.dataloaders(path)\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.396378\n1.538527\n0.522936\n00:24\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.393517\n1.140603\n0.440367\n00:22\n\n\n1\n1.261823\n0.996967\n0.357798\n00:23\n\n\n2\n1.069076\n0.967244\n0.339450\n00:23\n\n\n3\n0.934776\n0.965879\n0.348624\n00:23\n\n\n\n\n\nTo visualize the mistakes the errors the model makes, we create a confusion matrix.\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=5)",
    "crumbs": [
      "Deep Learning",
      "2 - Which member of 'The Beatles' are you?"
    ]
  },
  {
    "objectID": "fastai-2.html#step-3-turn-the-model-into-an-online-application",
    "href": "fastai-2.html#step-3-turn-the-model-into-an-online-application",
    "title": "Step 1: Download images of the Beatles using DuckDuckGo",
    "section": "Step 3: Turn the model into an online application",
    "text": "Step 3: Turn the model into an online application\nWe save the architecure and the learned parameters of our model.\n\nlearn.export()\n\n\npath = Path()\npath.ls(file_exts='.pkl')\n\n(#1) [Path('export.pkl')]\n\n\nWe can then create an inference learner from this exported file.\n\nlearn_inf = load_learner(path/'export.pkl')",
    "crumbs": [
      "Deep Learning",
      "2 - Which member of 'The Beatles' are you?"
    ]
  },
  {
    "objectID": "mathematics-polyfold-gromov-witten-theory.html",
    "href": "mathematics-polyfold-gromov-witten-theory.html",
    "title": "Polyfold Gromov–Witten theory",
    "section": "",
    "text": "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Standard Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%mathbb \n%greek \n%GREEK \n%cal \n%tilde \n%bar % \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Math Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%compactified moduli space \n% % % % %SYMPLECTIC GEOMETRY % % % % % \n% % % % %Hat Delbar % % % % % \n% % % % %COLORS % % % % %\n% % % % %GROMOV-WITTEN LANGUAGE % % % % % \n% % % % %THOM LANGUAGE % % % % % \n% % % % %POLYFOLD LANGUAGE % % % % %"
  },
  {
    "objectID": "mathematics-polyfold-gromov-witten-theory.html#history-of-the-gromovwitten-axioms",
    "href": "mathematics-polyfold-gromov-witten-theory.html#history-of-the-gromovwitten-axioms",
    "title": "Polyfold Gromov–Witten theory",
    "section": "History of the Gromov–Witten axioms",
    "text": "History of the Gromov–Witten axioms\nIn 1985 Gromov published the paper “Pseudo holomorphic curves in symplectic manifolds”, laying the foundations for the modern study of pseudo holomorphic curves (also know as \\(J\\)-holomorphic curves) in symplectic topology (Gromov 1985). In this paper, Gromov proved a compactness result for the moduli space of \\(J\\)-holomorphic curves in a fixed homology class. This paper contained antecedents to the modern notion of the Gromov–Witten invariants in the proofs of the nonsqueezing theorem and the uniqueness of symplectic structures on \\(\\mathbb{C}P^2\\).\nAround 1988, inspired by Floer’s study of gauge theory on three manifolds, Witten introduced the topological sigma model (Floer 1988; Witten 1988). The invariants of this model are the “\\(k\\)-point correlation functions”, another precursor to the modern notion of the Gromov–Witten invariants. Witten also observed some of the relationships between these invariants and possible degenerations of Riemann surfaces (Witten 1991). Further precursors to the notion of the Gromov–Witten invariants can also be seen in McDuff’s classification of symplectic ruled surfaces (McDuff 1991).\nIn 1993 Ruan gave a modern definition of the genus zero Gromov–Witten invariants for semipositive symplectic manifolds (Ruan 1996, 1994). At the end of 1993, Ruan and Tian established the associativity of the quantum product for semipositive symplectic manifolds, giving a mathematical basis to the composition law of Witten’s topological sigma model (Ruan and Tian 1995).\nIn 1994 Kontsevich and Manin stated the Gromov–Witten axioms, given as a list of formal relations between the Gromov–Witten invariants (Kontsevich and Manin 1994). At the time it was not possible for Kontsevich and Manin to give a proof of the relations they listed; the definition of the Gromov–Witten invariant (complete with homology classes from a Deligne–Mumford space) would require in addition new ideas involving “stable maps” (Kontsevich 1995). Hence they used to term “axiom” with the presumed meaning “to take for assumption without proof”/ “to use as a premise for further reasoning”. And indeed, from these starting assumptions they were able to establish foundational results in enumerative geometry, answers to esoteric questions such as:\n\nKontsevich’s recursion formula. Let \\(d\\geq 1\\). How many degree \\(d\\) rational curves in \\(\\mathbb{C}P^2\\) pass through \\(3d - 1\\) points in general position?\n\nMoreover, in this paper they outlined some of the formal consequences of the axioms by demonstrating how to combine the invariants into a Gromov–Witten potential, and interpret the axioms as differential equations which the potential satisfies.\nTo varying extents, this work has predated the construction of a well-defined Gromov–Witten invariant in symplectic geometry for \\(J\\)-holomorphic curves of arbitrary genus, and for all closed symplectic manifolds. Efforts to construct a well-defined Gromov–Witten invariant constitute an ever growing list of publications, including but not limited to the following: (Li and Tian 1998; Fukaya and Ono 1999; Fukaya et al. 2012; Siebert 1996; Cieliebak and Mohnke 2007; McDuff and Wehrheim 2012, 2018, 2017; Ionel and Parker 2013; Pardon 2016). A discussion of some of the difficulties inherent in these approaches can be found in (Fabert et al. 2016). Similarly, there have been several efforts to prove the Gromov–Witten axioms (Fukaya and Ono 1999; McDuff and Salamon 2012; Castellano 2016).\nOver the past two decades, Hofer, Wysocki, and Zehnder have developed a new approach to resolving transversality issues that arise in the study of \\(J\\)-holomorphic curves in symplectic geometry called polyfold theory (Hofer, Wysocki, and Zehnder 2007, 2009a, 2009b, 2017a, 2010b, n.d., 2010a, 2017b). This approach has been successful in constructing a well-defined Gromov–Witten invariant (Hofer, Wysocki, and Zehnder 2017a)."
  },
  {
    "objectID": "mathematics-polyfold-gromov-witten-theory.html#what-is-a-gromovwitten-invariant",
    "href": "mathematics-polyfold-gromov-witten-theory.html#what-is-a-gromovwitten-invariant",
    "title": "Polyfold Gromov–Witten theory",
    "section": "What is a Gromov–Witten invariant?",
    "text": "What is a Gromov–Witten invariant?\nLet \\((M,\\omega)\\) be a closed symplectic manifold of dimension \\(\\dim M = 2n\\), and let \\(J\\) be a \\(\\omega\\)-compatible almost complex structure. For a fixed homology class \\(A\\in H_2(M,{\\mathbb Z})\\), and for fixed integers \\(g\\geq 0\\), \\(k\\geq 0\\), we consider the set of \\(J\\)-holomorphic curves:\n\\[\n    {\\mathcal M}_{A,g,k}(J) :=\n    \\left\\{\n    \\begin{array}{c}\n        u: (\\Sigma_g,j) \\to M \\\\\n        \\{z_1,\\ldots,z_k\\}\\in \\Sigma_g\n    \\end{array}\n    \\biggm|\n    \\begin{array}{c}\n        \\tfrac{1}{2} (du+J\\circ du\\circ j)=0 \\\\\n        u_*[\\Sigma_g] = A\n    \\end{array}\n    \\right\\}\n    \\biggm/\n    \\begin{array}{l}\n        u \\sim u\\circ \\phi, \\\\\n        \\phi\\in \\text{Aut}\n    \\end{array}\n\\]\nconsisting of smooth maps \\(u:(\\Sigma_g,j)\\to M\\) which satisfy the Cauchy–Riemann equation modulo reparametrization; here \\((\\Sigma_g,j)\\) is a genus \\(g\\) Riemann surface and \\(\\text{Aut}\\) is the automorphism group of the Riemann surface \\((\\Sigma_g,j)\\) which preserves the ordering of the marked points.\nGromov proved this set has a natural compactification in (Gromov 1985), which was later refined into the stable map compactification of Kontsevich in (Kontsevich 1995), and thus we may also consider its compactification, the Gromov–Witten moduli space:\n\\[\n    \\bar{\\mathcal{M}}_{A,g,k} (J) := {\\mathcal M}_{A,g,k} (J) \\sqcup \\{\\text{stable nodal $J$-holomorphic curves}\\}.\n\\]\nWe seek to use this space to construct invariants of the symplectic manifold \\(M\\). To this end, we define the evaluation map which evaluates a stable curve on each marked point:\n\\[\n    ev: \\bar{\\mathcal{M}}_{A,g,k} (J) \\to M\\times \\cdots \\times M.\n\\]\nOn the top stratum of non-noded stable \\(J\\)-holomorphic curves it is given by\n\\[\n    ev\\left([(u,z_1,\\ldots,z_k)] \\right): = (u(z_1),\\ldots, u(z_k)).\n\\]\nWith the fixed integers \\(g \\geq 0\\), \\(k \\geq 3\\) we also consider the associated Deligne–Mumford space, the natural compactification of the space of configurations of a complex structure and \\(k\\)-marked points on a genus \\(g\\) Riemann surface modulo biholomorphic equivalence:\n\\[\n    \\bar{\\mathcal{M}}_{g,k} := \\text{cl} \\left(\\{ j, \\{z_1,\\ldots,z_k\\}\\in \\Sigma_g \\mid j \\text{ complex structure on } \\Sigma_g, z_i\\neq z_j \\text{ if } i \\neq j\\} / \\text{Aut} \\right).\n\\]\nWhen \\(g = 0\\) this space is a finite-dimensional manifold, and when \\(g\\neq 0\\) this space is a finite-dimensional orbifold, in either case of dimension \\(\\text{dim}\\) \\(\\bar{\\mathcal{M}}_{g,k} = 6g - 6 + 2k\\) We may define a projection map from the GW-moduli space to the DM-space which forgets the curve which maps to \\(M\\) and which stabilizes the resulting unstable domain components:\n\\[\n    \\pi: \\bar{\\mathcal{M}}_{A,g,k} (J) \\to \\bar{\\mathcal{M}}_{g,k}.\n\\]\nOn the top stratum of non-noded stable \\(J\\)-holomorphic curves it forgets the map \\(u\\) and is given by\n\\[\n    \\pi\\left([(u,j,z_1,\\ldots,z_k)]\\right) := [(j,z_1,\\ldots,z_k)].\n\\]\nThe traditional interpretation of a Gromov–Witten invariant is the (supposedly) finite count of \\(J\\)-holomorphic curves which at the \\(i\\)th-marked point pass through a submanifold \\({\\mathcal X}_i \\subset M\\) and whose marked point configuration is restricted by the projection map to a suborbifold \\({\\mathcal B}\\subset \\bar{\\mathcal{M}}_{g,k}\\).\nSuch an intersection number should depend only on the homology classes of the submanifolds, and should be independent of the almost complex structure. This count can be packaged algebraically as a homomorphism:\n\\[\n    \\mathop{\\mathrm{GW}}_{A,g,k} : H_*(M;{\\mathbb Q})^{\\otimes k} \\times H_*(\\bar{\\mathcal{M}}_{g,k};{\\mathbb Q}) \\to {\\mathbb Q}.\n\\]\nA foundational problem in symplectic geometry is to actually show that such a GW-invariant is well-defined. Ideally, we would like to define a GW-invariant rigorously via an intersection number:\n\\[\n\\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) = (ev\\times \\pi) (\\bar{\\mathcal{M}}_{A,g,k} (J)) \\cdot ({\\mathcal X}_1\\times \\cdots \\times {\\mathcal X}_k \\times {\\mathcal B}),\n\\]\nor as an integral:\n\\[\n\\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) = \\int_{\\bar{\\mathcal{M}}_{A,g,k}(J)} ev^* (\\mathop{\\mathrm{PD}}[{\\mathcal X}_1]\\wedge \\cdots \\wedge \\mathop{\\mathrm{PD}}[{\\mathcal X}_k]) \\wedge \\pi^* \\mathop{\\mathrm{PD}}[{\\mathcal B}],\n\\]\nor as a pairing with a (virtual) fundamental class:\n\\[\n\\mathop{\\mathrm{GW}}_{A,g,k} ([{\\mathcal X}_1],\\ldots,[{\\mathcal X}_k];[{\\mathcal B}]) = \\left\\langle (ev\\times\\pi)_* [\\bar{\\mathcal{M}}_{A,g,k}(J)], \\mathop{\\mathrm{PD}}[{\\mathcal X}_1\\times\\cdots\\times{\\mathcal X}_k\\times{\\mathcal B}] \\right\\rangle.\n\\]\nSuch definitions require additional structure on the GW-moduli space; an intersection number requires tangent spaces and notions of transversal intersection, an integral requires smooth partitions of unity and notions of differential forms, and a (virtual) fundamental class requires a distinguished homology class on the topological space.\nHowever, a priori, the GW-moduli space only has the structure of a compact topological space, and this alone is insufficient to define any of the above. More structure is needed."
  },
  {
    "objectID": "mathematics-polyfold-gromov-witten-theory.html#the-classical-pseudocycle-gromovwitten-invariant-for-genus-zero-and-semipositive-symplectic-manifolds",
    "href": "mathematics-polyfold-gromov-witten-theory.html#the-classical-pseudocycle-gromovwitten-invariant-for-genus-zero-and-semipositive-symplectic-manifolds",
    "title": "Polyfold Gromov–Witten theory",
    "section": "The classical pseudocycle Gromov–Witten invariant for genus-zero and semipositive symplectic manifolds",
    "text": "The classical pseudocycle Gromov–Witten invariant for genus-zero and semipositive symplectic manifolds"
  },
  {
    "objectID": "mathematics-polyfold-gromov-witten-theory.html#the-polyfold-gromovwitten-invariant-for-arbitrary-genus-and-general-symplectic-manifolds",
    "href": "mathematics-polyfold-gromov-witten-theory.html#the-polyfold-gromovwitten-invariant-for-arbitrary-genus-and-general-symplectic-manifolds",
    "title": "Polyfold Gromov–Witten theory",
    "section": "The polyfold Gromov–Witten invariant for arbitrary genus and general symplectic manifolds",
    "text": "The polyfold Gromov–Witten invariant for arbitrary genus and general symplectic manifolds\nPolyfold theory, developed by Hofer, Wysocki, and Zehnder, is a modern new approach to resolving transversality issues that arise in attempts to solve moduli space problems in symplectic geometry. The polyfold theoretic approach to solving a moduli space problem is to recast the problem into familiar terms from differential geometry. To do this, we may construct a “Gromov–Witten polyfold” \\({\\mathcal Z}_{A,g,k}\\)—a massive, infinite-dimensional ambient space, designed to contain the entire unperturbed Gromov–Witten moduli space \\(\\bar{\\mathcal{M}}_{A,g,k}(J)\\) as a compact subset. We may furthermore construct a “strong polyfold bundle” \\({\\mathcal W}_{A,g,k}\\) over \\({\\mathcal Z}_{A,g,k}\\); the Cauchy–Riemann operator then defines a “scale smooth Fredholm section” of this bundle, \\(\\bar{\\partial}_J:{\\mathcal Z}_{A,g,k} \\to {\\mathcal W}_{A,g,k}\\), such that \\(\\smash{\\bar{\\partial}_J}\\vphantom{\\partial}^{-1}(0) = \\bar{\\mathcal{M}}_{A,g,k}(J)\\). We can construct “abstract perturbations” \\(p\\) of this section such that \\(\\bar{\\partial}_J+p\\) is transverse to the zero section and such that \\((\\bar{\\partial}_J+p)^{-1}(0)\\) is a compact set. In this way, we may take a scale smooth Fredholm section and “regularize” the unperturbed Gromov–Witten moduli space yielding a perturbed Gromov–Witten moduli space \\({\\mathcal S}_{A,g,k}(p):= (\\bar{\\partial}_J+p)^{-1}(0)\\) which has the structure of a compact oriented “weighted branched orbifold”.\n\\[\n        \\begin{array}{c}\n        \\bar{\\mathcal{M}}_{A,g,k}(J) = \\bar{\\partial}_J^{-1}(0)        \\\\\n        \\text{\\small{compact topological space}} \\\\\n        \\end{array}\n        \\xrightarrow{\\text{\"polyfold regularization\"}}\n        \\begin{array}{c}\n            {\\mathcal S}_{A,g,k}(p):=(\\bar{\\partial}_J+p)^{-1}(0) \\\\\n            \\text{\\small{compact \"weighted branched orbifold\"}}\n        \\end{array}\n\\]\nThis approach has been successful in giving a well-defined Gromov–Witten invariant for curves of arbitrary genus, and for all closed symplectic manifolds. Suppose that \\(2g+k\\geq 3\\), and consider the following diagram of smooth maps between the perturbed Gromov–Witten moduli space \\({\\mathcal S}_{A,g,k}(p)\\), the \\(k\\)-fold product manifold \\(M^k\\), and the Deligne–Mumford orbifold \\(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\\):\n\\[\n    \\begin{align*}\n        &{\\mathcal S}_{A,g,k}(p) \\xrightarrow{ev_1\\times\\cdots\\times ev_k} M^k\\\\\n        &\\pi \\bigg{\\downarrow} \\\\\n        &\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}\n    \\end{align*}\n\\]\nHere \\(ev_i\\) is evaluation at the \\(i\\)th-marked point, and \\(\\pi\\) is the projection map to the Deligne–Mumford space which forgets the stable map solution and stabilizes the resulting nodal Riemann surface by contracting unstable components.\nConsider homology classes \\(\\alpha_1,\\ldots, \\alpha_k \\in H_* (M;{\\mathbb Q})\\) and \\(\\beta\\in H_* (\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k};{\\mathbb Q})\\). We can represent the Poincar'e duals of the \\(\\alpha_i\\) and \\(\\beta\\) by closed differential forms in the de Rahm cohomology groups, \\(\\mathop{\\mathrm{PD}}(\\alpha_i)\\in H^*_{\\mathop{\\mathrm{dR}}} (M)\\) and \\(\\mathop{\\mathrm{PD}}(\\beta)\\in H^*_{\\mathop{\\mathrm{dR}}}(\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k})\\). By pulling back via the evaluation and projection maps, we obtain a closed \\(\\text{sc}\\)-smooth differential form\n\\[\n    ev_1^* \\mathop{\\mathrm{PD}}(\\alpha_1) \\wedge \\cdots \\wedge ev_k^* \\mathop{\\mathrm{PD}}(\\alpha_k) \\wedge\\pi^* \\mathop{\\mathrm{PD}}(\\beta) \\in H^*_{\\mathop{\\mathrm{dR}}} ({\\mathcal Z}_{A,g,k}).\n\\]\nTheorem. (Hofer, Wysocki, and Zehnder 2017a, Thm. 1.12) The polyfold Gromov–Witten invariant is the homomorphism\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} : H_* (M;{\\mathbb Q})^{\\otimes k} \\otimes H_* (\\smash{\\bar{\\mathcal{M}}}\\vphantom{\\mathcal{M}}^{\\text{log}}_{g,k}; {\\mathbb Q}) \\to {\\mathbb Q}\n\\]\ndefined via the “branched integration” of (Hofer, Wysocki, and Zehnder 2010a):\n\\[\n        \\mathop{\\mathrm{GW}}_{A,g,k} (\\alpha_1,\\ldots,\\alpha_k;\\beta) : = \\int_{{\\mathcal S}_{A,g,k}(p)} ev_1^* \\mathop{\\mathrm{PD}}(\\alpha_1) \\wedge \\cdots \\wedge ev_k^* \\mathop{\\mathrm{PD}}(\\alpha_k) \\wedge\\pi^* \\mathop{\\mathrm{PD}}(\\beta).\n\\]\nThis invariant does not depend on the choice of perturbation.\n\nReferences\n\n\nCastellano, Robert. 2016. Kuranishi Atlases and Genus Zero Gromov–Witten Invariants. ProQuest LLC, Ann Arbor, MI. http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:10096865 .\n\n\nCieliebak, Kai, and Klaus Mohnke. 2007. “Symplectic Hypersurfaces and Transversality in Gromov–Witten Theory.” J. Symplectic Geom. 5 (3): 281–356. http://projecteuclid.org/euclid.jsg/1210083200.\n\n\nFabert, Oliver, Joel W. Fish, Roman Golovko, and Katrin Wehrheim. 2016. “Polyfolds: A First and Second Look.” EMS Surv. Math. Sci. 3 (2): 131–208. https://doi.org/10.4171/EMSS/16.\n\n\nFloer, Andreas. 1988. “An Instanton-Invariant for \\(3\\)-Manifolds.” Comm. Math. Phys. 118 (2): 215–40. http://projecteuclid.org/euclid.cmp/1104161987.\n\n\nFukaya, Kenji, Yong-Geun Oh, Hiroshi Ohta, and Kaoru Ono. 2012. “Technical details on Kuranishi structure and virtual fundamental chain.” arXiv e-Prints. September 2012. https://arxiv.org/abs/1209.4410.\n\n\nFukaya, Kenji, and Kaoru Ono. 1999. “Arnold Conjecture and Gromov–Witten Invariant for General Symplectic Manifolds.” In The Arnoldfest (Toronto, ON, 1997), 24:173–90. Fields Inst. Commun. Amer. Math. Soc., Providence, RI.\n\n\nGromov, M. 1985. “Pseudo Holomorphic Curves in Symplectic Manifolds.” Invent. Math. 82 (2): 307–47. https://doi.org/10.1007/BF01388806.\n\n\nHofer, Helmut, Kris Wysocki, and Eduard Zehnder. 2007. “A General Fredholm Theory. I. A Splicing-Based Differential Geometry.” J. Eur. Math. Soc. (JEMS) 9 (4): 841–76. https://doi.org/10.4171/JEMS/99.\n\n\n———. 2009a. “A General Fredholm Theory. II. Implicit Function Theorems.” Geom. Funct. Anal. 19 (1): 206–93. https://doi.org/10.1007/s00039-009-0715-x.\n\n\n———. 2009b. “A General Fredholm Theory. III. Fredholm Functors and Polyfolds.” Geom. Topol. 13 (4): 2279–2387. https://doi.org/10.2140/gt.2009.13.2279.\n\n\n———. 2010a. “Integration Theory on the Zero Sets of Polyfold Fredholm Sections.” Math. Ann. 346 (1): 139–98. https://doi.org/10.1007/s00208-009-0393-x.\n\n\n———. 2010b. “Sc-Smoothness, Retractions and New Models for Smooth Spaces.” Discrete Contin. Dyn. Syst. 28 (2): 665–788. https://doi.org/10.3934/dcds.2010.28.665.\n\n\n———. 2017a. “Applications of Polyfold Theory I: The Polyfolds of Gromov– Witten Theory.” Mem. Amer. Math. Soc. 248 (1179): v+218. https://doi.org/10.1090/memo/1179.\n\n\n———. 2017b. “Polyfold and Fredholm theory.” arXiv e-Prints. July 2017. https://arxiv.org/abs/1707.08941.\n\n\n———. n.d. “Deligne–Mumford-Type Spaces with a View Towards Symplectic Field Theory.”\n\n\nIonel, Eleny-Nicoleta, and Thomas H. Parker. 2013. “A natural Gromov–Witten virtual fundamental class.” arXiv e-Prints. February 2013. https://arxiv.org/abs/1302.3472.\n\n\nKontsevich, Maxim. 1995. “Enumeration of Rational Curves via Torus Actions.” In The Moduli Space of Curves (Texel Island, 1994), 129:335–68. Progr. Math. Birkhäuser Boston, Boston, MA. https://doi.org/10.1007/978-1-4612-4264-2_12.\n\n\nKontsevich, Maxim, and Yuri Manin. 1994. “Gromov–Witten Classes, Quantum Cohomology, and Enumerative Geometry.” Comm. Math. Phys. 164 (3): 525–62. http://projecteuclid.org/euclid.cmp/1104270948.\n\n\nLi, Jun, and Gang Tian. 1998. “Virtual Moduli Cycles and Gromov–Witten Invariants of General Symplectic Manifolds.” In Topics in Symplectic \\(4\\)-Manifolds (Irvine, CA, 1996), 47–83. First Int. Press Lect. Ser., i. Int. Press, Cambridge, MA.\n\n\nMcDuff, Dusa. 1991. “Symplectic Manifolds with Contact Type Boundaries.” Invent. Math. 103 (3): 651–71. https://doi.org/10.1007/BF01239530.\n\n\nMcDuff, Dusa, and Dietmar Salamon. 2012. \\(J\\)-Holomorphic Curves and Symplectic Topology. Second. Vol. 52. American Mathematical Society Colloquium Publications. American Mathematical Society, Providence, RI.\n\n\nMcDuff, Dusa, and Katrin Wehrheim. 2012. “Kuranishi atlases with trivial isotropy - the 2013 state of affairs.” arXiv e-Prints. August 2012. https://arxiv.org/abs/1208.1340.\n\n\n———. 2017. “The Topology of Kuranishi Atlases.” Proc. Lond. Math. Soc. (3) 115 (2): 221–92. https://doi.org/10.1112/plms.12032.\n\n\n———. 2018. “The Fundamental Class of Smooth Kuranishi Atlases with Trivial Isotropy.” J. Topol. Anal. 10 (1): 71–243. https://doi.org/10.1142/S1793525318500048.\n\n\nPardon, John. 2016. “An Algebraic Approach to Virtual Fundamental Cycles on Moduli Spaces of Pseudo-Holomorphic Curves.” Geom. Topol. 20 (2): 779–1034. https://doi.org/10.2140/gt.2016.20.779.\n\n\nRuan, Yongbin. 1994. “Symplectic Topology on Algebraic \\(3\\)-Folds.” J. Differential Geom. 39 (1): 215–27. http://projecteuclid.org/euclid.jdg/1214454682.\n\n\n———. 1996. “Topological Sigma Model and Donaldson-Type Invariants in Gromov Theory.” Duke Math. J. 83 (2): 461–500. https://doi.org/10.1215/S0012-7094-96-08316-7.\n\n\nRuan, Yongbin, and Gang Tian. 1995. “A Mathematical Theory of Quantum Cohomology.” J. Differential Geom. 42 (2): 259–367. http://projecteuclid.org/euclid.jdg/1214457234.\n\n\nSiebert, Bernd. 1996. “Gromov–Witten invariants of general symplectic manifolds.” Eprint arXiv:dg-Ga/960800. August 1996. https://arxiv.org/abs/dg-ga/9608005.\n\n\nWitten, Edward. 1988. “Topological Sigma Models.” Comm. Math. Phys. 118 (3): 411–49. http://projecteuclid.org/euclid.cmp/1104162092.\n\n\n———. 1991. “Two-Dimensional Gravity and Intersection Theory on Moduli Space.” In Surveys in Differential Geometry (Cambridge, MA, 1990), 243–310. Lehigh Univ., Bethlehem, PA."
  }
]